{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae53869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¥ Loading dataset splits...\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g19_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g17_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g12_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g20_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c07.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g18_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g21_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g12_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g18_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g18_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g01_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g01_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g07_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g09_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g22_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g22_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g16_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g02_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g14_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g17_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g04_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g15_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g15_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g07_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g06_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g08_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g10_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g13_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g15_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g10_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g24_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g10_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g05_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g04_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g05_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g17_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g24_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g01_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g24_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g23_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g07_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g22_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g11_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g11_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g23_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g07_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g01_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g15_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g05_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g18_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g14_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g13_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g02_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g18_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g03_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g12_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g04_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g12_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g17_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g15_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g06_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g21_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g03_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g19_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g07_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g01_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g11_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g06_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g04_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g08_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c07.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g05_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g14_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g25_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g12_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g08_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g25_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g12_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g02_c07.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g12_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g25_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g11_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g04_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g17_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g24_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g22_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g02_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g10_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g02_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g03_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g11_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g22_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g17_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g25_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g21_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g07_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g02_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g14_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g08_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g09_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g07_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g08_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g14_c03.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g11_c05.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c06.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g17_c02.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g24_c04.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "[INFO] Opening video: /Users/chocalingamlakshmanan/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g17_c01.avi\n",
      "[INFO] Frame limit reached: 50\n",
      "[INFO] Frames processed: 50\n",
      "[INFO] Final feature vector length: 399\n",
      "ðŸŽ¯ Extracting features...\n",
      "[INFO] Opening video: [[1.52295644e-01 3.85302709e-04 2.54112083e-04 ... 1.56250002e-03\n",
      "  1.83593750e-03 1.43229161e-04]\n",
      " [9.83217015e-01 1.32993595e-01 2.03185473e-02 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.67801384e-01 7.48797536e-01 1.88086903e-01 ... 2.60416673e-05\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.78341163e-03 8.32495054e-03 9.67144068e-01 ... 7.81249983e-05\n",
      "  3.90624991e-05 0.00000000e+00]\n",
      " [5.48773361e-01 4.80098687e-01 4.73922604e-02 ... 1.30208336e-05\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.88398038e-01 2.63305965e-01 1.89808327e-02 ... 2.60416673e-05\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) :-1: error: (-5:Bad argument) in function 'VideoCapture'\n> Overload resolution failed:\n>  - Expected 'filename' to be a str or path-like object\n>  - VideoCapture() missing required argument 'apiPreference' (pos 2)\n>  - Argument 'index' is required to be an integer\n>  - VideoCapture() missing required argument 'apiPreference' (pos 2)\n>  - VideoCapture() missing required argument 'apiPreference' (pos 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 109\u001b[0m\n\u001b[1;32m    105\u001b[0m test_videos, y_test \u001b[38;5;241m=\u001b[39m load_split_data(split_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸŽ¯ Extracting features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mextract_video_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_videos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m X_val \u001b[38;5;241m=\u001b[39m extract_video_features(val_videos)\n\u001b[1;32m    111\u001b[0m X_test \u001b[38;5;241m=\u001b[39m extract_video_features(test_videos)\n",
      "File \u001b[0;32m~/Desktop/Video-analytics-assignment/Student_2024ab05275_Video_Classification/code/feature_extraction.py:254\u001b[0m, in \u001b[0;36mextract_video_features\u001b[0;34m(video_path, color_space, bins, max_frames)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03mExtract all classical features including temporal\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03mstatistics from a video.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    253\u001b[0m log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpening video: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 254\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoCapture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot open video: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.12.0) :-1: error: (-5:Bad argument) in function 'VideoCapture'\n> Overload resolution failed:\n>  - Expected 'filename' to be a str or path-like object\n>  - VideoCapture() missing required argument 'apiPreference' (pos 2)\n>  - Argument 'index' is required to be an integer\n>  - VideoCapture() missing required argument 'apiPreference' (pos 2)\n>  - VideoCapture() missing required argument 'apiPreference' (pos 2)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "====================================================\n",
    "Classical Machine Learning Pipeline for Video Actions\n",
    "====================================================\n",
    "\n",
    "This script implements and compares three classical\n",
    "machine learning algorithms for video-based activity\n",
    "recognition using hand-crafted features.\n",
    "\n",
    "Algorithms Implemented\n",
    "----------------------------------------------------\n",
    "1. Support Vector Machine (Linear + RBF)\n",
    "2. Random Forest Classifier\n",
    "3. k-Nearest Neighbors (k-NN)\n",
    "\n",
    "Features are extracted using:\n",
    "- feature_extraction.py (per-video feature extraction)\n",
    "- data_loader.py (train/val/test splits)\n",
    "\n",
    "Author: Student_2024AB05275\n",
    "\"\"\"\n",
    "\n",
    "# ==================================================\n",
    "# STANDARD LIBRARY IMPORTS\n",
    "# ==================================================\n",
    "from typing import Dict\n",
    "import warnings\n",
    "\n",
    "# ==================================================\n",
    "# THIRD-PARTY IMPORTS\n",
    "# ==================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# ==================================================\n",
    "# PROJECT IMPORTS\n",
    "# ==================================================\n",
    "from feature_extraction import extract_video_features\n",
    "from data_loader import load_split_data\n",
    "\n",
    "# ==================================================\n",
    "# GLOBAL CONFIGURATION\n",
    "# ==================================================\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_STATE = 42\n",
    "CV_FOLDS = 5\n",
    "MAX_FRAMES = 50   # Frame cap for consistency & speed\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ==================================================\n",
    "def extract_features_for_split(video_paths):\n",
    "    \"\"\"\n",
    "    Extract features for a list of video files.\n",
    "\n",
    "    Each video is processed independently using\n",
    "    extract_video_features(), producing a fixed-length\n",
    "    feature vector per video.\n",
    "\n",
    "    Args:\n",
    "        video_paths (list[str]): paths to video files\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Feature matrix of shape (N, D)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for idx, video_path in enumerate(video_paths):\n",
    "        print(f\"[INFO] Processing video {idx + 1}/{len(video_paths)}\")\n",
    "        feature_vector = extract_video_features(\n",
    "            str(video_path),\n",
    "            max_frames=MAX_FRAMES\n",
    "        )\n",
    "        features.append(feature_vector)\n",
    "\n",
    "    return np.vstack(features)\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: BaseEstimator,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a trained model using multiple metrics.\n",
    "\n",
    "    Returns:\n",
    "        dict: accuracy, precision, recall, f1-score\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"recall\": recall_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_confusion(model, X_test, y_test, title: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot confusion matrix for a classifier.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_test, model.predict(X_test))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# DATA LOADING & FEATURE EXTRACTION\n",
    "# ==================================================\n",
    "print(\"\\nðŸ“¥ Loading dataset splits...\")\n",
    "\n",
    "train_videos, y_train = load_split_data(split_name=\"train\")\n",
    "val_videos, y_val = load_split_data(split_name=\"val\")\n",
    "test_videos, y_test = load_split_data(split_name=\"test\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Extracting features... (this may take time on first run)\")\n",
    "\n",
    "X_train = extract_features_for_split(train_videos)\n",
    "X_val = extract_features_for_split(val_videos)\n",
    "X_test = extract_features_for_split(test_videos)\n",
    "\n",
    "print(f\"\\nTrain feature shape: {X_train.shape}\")\n",
    "print(f\"Test feature shape : {X_test.shape}\")\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 1ï¸âƒ£ SUPPORT VECTOR MACHINE (LINEAR + RBF)\n",
    "# ==================================================\n",
    "print(\"\\nðŸš€ Training Support Vector Machine...\")\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC())\n",
    "])\n",
    "\n",
    "svm_param_grid = [\n",
    "    {\"svm__kernel\": [\"linear\"], \"svm__C\": [0.1, 1, 10]},\n",
    "    {\n",
    "        \"svm__kernel\": [\"rbf\"],\n",
    "        \"svm__C\": [0.1, 1, 10],\n",
    "        \"svm__gamma\": [0.01, 0.1, 1],\n",
    "    },\n",
    "]\n",
    "\n",
    "svm_grid = GridSearchCV(\n",
    "    svm_pipeline,\n",
    "    svm_param_grid,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "svm_grid.fit(X_train, y_train)\n",
    "best_svm = svm_grid.best_estimator_\n",
    "\n",
    "svm_metrics = evaluate_model(best_svm, X_test, y_test)\n",
    "plot_confusion(best_svm, X_test, y_test, \"SVM Confusion Matrix\")\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 2ï¸âƒ£ RANDOM FOREST CLASSIFIER\n",
    "# ==================================================\n",
    "print(\"\\nðŸŒ² Training Random Forest...\")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [10, 20, None],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    rf,\n",
    "    rf_param_grid,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "rf_metrics = evaluate_model(best_rf, X_test, y_test)\n",
    "plot_confusion(best_rf, X_test, y_test, \"Random Forest Confusion Matrix\")\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 3ï¸âƒ£ K-NEAREST NEIGHBORS\n",
    "# ==================================================\n",
    "print(\"\\nðŸ“ Training k-Nearest Neighbors...\")\n",
    "\n",
    "knn_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "knn_param_grid = {\n",
    "    \"knn__n_neighbors\": [3, 5, 7, 9],\n",
    "    \"knn__metric\": [\"euclidean\", \"manhattan\"],\n",
    "}\n",
    "\n",
    "knn_grid = GridSearchCV(\n",
    "    knn_pipeline,\n",
    "    knn_param_grid,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "knn_grid.fit(X_train, y_train)\n",
    "best_knn = knn_grid.best_estimator_\n",
    "\n",
    "knn_metrics = evaluate_model(best_knn, X_test, y_test)\n",
    "plot_confusion(best_knn, X_test, y_test, \"k-NN Confusion Matrix\")\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# ðŸ“Š COMPARATIVE ANALYSIS\n",
    "# ==================================================\n",
    "print(\"\\nðŸ“Š Comparative Model Analysis\")\n",
    "\n",
    "results = {\n",
    "    \"SVM\": svm_metrics,\n",
    "    \"Random Forest\": rf_metrics,\n",
    "    \"k-NN\": knn_metrics,\n",
    "}\n",
    "\n",
    "metrics_names = list(next(iter(results.values())).keys())\n",
    "model_names = list(results.keys())\n",
    "\n",
    "metrics_matrix = np.array(\n",
    "    [[results[m][metric] for metric in metrics_names] for m in model_names]\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Bar Plot Comparison\n",
    "# --------------------------\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, model in enumerate(model_names):\n",
    "    plt.bar(\n",
    "        x + i * width,\n",
    "        metrics_matrix[i],\n",
    "        width,\n",
    "        label=model,\n",
    "    )\n",
    "\n",
    "plt.xticks(x + width, metrics_names)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Classical ML Model Performance Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# ðŸ† FINAL DYNAMIC SUMMARY\n",
    "# ==================================================\n",
    "best_model = max(\n",
    "    results.items(),\n",
    "    key=lambda item: item[1][\"f1_score\"],\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ† Final Summary\")\n",
    "for model, metrics in results.items():\n",
    "    print(f\"\\n{model}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k:<10}: {v:.4f}\")\n",
    "\n",
    "print(\n",
    "    f\"\\nâœ… Best overall model based on macro F1-score: \"\n",
    "    f\"{best_model[0]}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c5479",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
