{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa53da25",
   "metadata": {},
   "source": [
    "PART B: DEEP LEARNING VIDEO CLASSIFICATION (REAL DATA)\n",
    "\n",
    "This script implements:\n",
    "1. 2D CNN (ResNet-18) + Temporal Pooling\n",
    "2. 3D CNN (R(2+1)D-18)\n",
    "\n",
    "Dataset:\n",
    "- UCF-style directory\n",
    "- Predefined train/test splits\n",
    "\n",
    "Evaluation:\n",
    "- Accuracy\n",
    "- Precision (macro)\n",
    "- Recall (macro)\n",
    "- F1-score (macro)\n",
    "- Confusion Matrix\n",
    "- Training time\n",
    "- Inference time per video\n",
    "\n",
    "Author: 2024ab05275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7155a69f-1727-4343-8b54-45bfac7cbf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.10 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.11.3)\n",
      "Requirement already satisfied: torch>=2.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (2.3.0+cu121)\n",
      "Requirement already satisfied: torchvision>=0.15 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.18.0+cu121)\n",
      "Collecting opencv-python-headless (from -r requirements.txt (line 10))\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.3 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.22.0)\n",
      "Requirement already satisfied: matplotlib>=3.7 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (3.8.4)\n",
      "Requirement already satisfied: seaborn>=0.13 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.66 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (4.66.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.15->-r requirements.txt (line 7)) (10.4.0)\n",
      "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.3->-r requirements.txt (line 11)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.3->-r requirements.txt (line 11)) (3.5.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 12)) (2.34.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 12)) (2024.7.2)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 12)) (24.1)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 12)) (0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7->-r requirements.txt (line 15)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7->-r requirements.txt (line 15)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7->-r requirements.txt (line 15)) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7->-r requirements.txt (line 15)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7->-r requirements.txt (line 15)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7->-r requirements.txt (line 15)) (2.9.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.13->-r requirements.txt (line 16)) (2.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn>=0.13->-r requirements.txt (line 16)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn>=0.13->-r requirements.txt (line 16)) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.7->-r requirements.txt (line 15)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0->-r requirements.txt (line 6)) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.0->-r requirements.txt (line 6)) (1.3.0)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf86cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# IMPORTS\n",
    "# ==========================================================\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Standard Library Imports\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "import os\n",
    "# File-system operations such as path checks and environment handling\n",
    "\n",
    "import time\n",
    "# Execution time measurement and performance benchmarking\n",
    "\n",
    "from pathlib import Path\n",
    "# Object-oriented and platform-independent file path management\n",
    "\n",
    "from typing import List, Tuple\n",
    "# Type annotations for improved readability and static analysis\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Scientific Computing & Computer Vision Libraries\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "# Numerical computation, array manipulation, and statistical operations\n",
    "\n",
    "import cv2\n",
    "# Video decoding, frame preprocessing, color-space conversion, and filtering\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PyTorch Core Framework\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "import torch\n",
    "# Tensor computation, GPU acceleration, and automatic differentiation\n",
    "\n",
    "import torch.nn as nn\n",
    "# Neural network layer definitions and model construction primitives\n",
    "\n",
    "import torch.optim as optim\n",
    "# Optimization algorithms for training neural networks\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Dataset abstraction and efficient batch-wise data loading\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Torchvision Utilities\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "from torchvision import models, transforms\n",
    "# Pretrained CNN backbones and image preprocessing pipelines\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Evaluation Metrics (Scikit-learn)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "# Classification performance metrics and confusion matrix analysis\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Visualization Libraries\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plotting utilities for training curves and comparative analysis\n",
    "\n",
    "import seaborn as sns\n",
    "# High-level statistical visualizations and heatmaps\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Project-Specific Model Architectures\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "from models import CNN2DTemporal, CNN3D, EarlyStopping\n",
    "# Custom deep learning models for video classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df9008d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "âœ… Project root: /home/jovyan/va-volume/Student_2024ab05275_Video_Classification\n",
      "âœ… Dataset root: /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset\n",
      "âœ… Local Weight Path : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/model/resnet18-f37072fd.pth\n",
      "----------------------------------------------------------\n",
      "ğŸš€ Running on device: cuda\n",
      "----------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# CONFIGURATION\n",
    "# ==========================================================\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Current file is inside /code\n",
    "CODE_DIR = Path.cwd()\n",
    "\n",
    "# Project root is one level above\n",
    "PROJECT_ROOT = CODE_DIR.parent\n",
    "\n",
    "DATASET_ROOT = PROJECT_ROOT / \"dataset\"\n",
    "SPLITS_DIR = DATASET_ROOT / \"splits\"\n",
    "\n",
    "LOCAL_WEIGHTS = os.path.join(PROJECT_ROOT, \"model\", \"resnet18-f37072fd.pth\")\n",
    "\n",
    "# Safety checks (VERY IMPORTANT)\n",
    "assert DATASET_ROOT.exists(), f\"Dataset not found at {DATASET_ROOT}\"\n",
    "assert SPLITS_DIR.exists(), f\"Splits folder not found at {SPLITS_DIR}\"\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(f\"âœ… Project root: {PROJECT_ROOT}\")\n",
    "print(f\"âœ… Dataset root: {DATASET_ROOT}\")\n",
    "print(f\"âœ… Local Weight Path : {LOCAL_WEIGHTS}\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "NUM_FRAMES = 16                 # Frames sampled per video\n",
    "IMG_SIZE = (224, 224)           # Required for pretrained CNNs\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸš€ Running on device: {DEVICE}\")\n",
    "print(\"----------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73aa49f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Scanning dataset root for class folders.....\n",
      "* Dataset root path: /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset\n",
      "----------------------------------------------------------\n",
      "* No of Class Folders Found : 3\n",
      "* Detected class folders (sorted):\n",
      "  - class_1_Basketball\n",
      "  - class_2_Biking\n",
      "  - class_3_WalkingWithDog\n",
      "----------------------------------------------------------\n",
      "* Final class-to-index mapping:\n",
      "  - class_1_Basketball â†’ 0\n",
      "  - class_2_Biking â†’ 1\n",
      "  - class_3_WalkingWithDog â†’ 2\n",
      "----------------------------------------------------------\n",
      "* Total number of classes: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# CLASS MAPPING (Derived from dataset folder names)\n",
    "# ==========================================================\n",
    "# This section automatically discovers class labels from the\n",
    "# dataset directory structure.\n",
    "#\n",
    "# Expected directory format:\n",
    "# DATASET_ROOT/\n",
    "# â”œâ”€â”€ class_0/\n",
    "# â”œâ”€â”€ class_1/\n",
    "# â”œâ”€â”€ class_2/\n",
    "# â””â”€â”€ ...\n",
    "#\n",
    "# Each \"class_*\" folder represents one target class.\n",
    "# ==========================================================\n",
    "\n",
    "print(\"* Scanning dataset root for class folders.....\")\n",
    "print(f\"* Dataset root path: {DATASET_ROOT}\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "# ----------------------------------------------------------\n",
    "# Step 1: Discover class directory names\n",
    "# ----------------------------------------------------------\n",
    "# - Iterate over all items inside DATASET_ROOT\n",
    "# - Keep only directories\n",
    "# - Keep only directory names that start with \"class_\"\n",
    "# - Sort them to ensure consistent class index assignment\n",
    "# ----------------------------------------------------------\n",
    "CLASS_NAMES = sorted([\n",
    "    d.name                      # Folder name (e.g., \"class_1\")\n",
    "    for d in DATASET_ROOT.iterdir()\n",
    "    if d.is_dir()                # Ensure it is a directory\n",
    "    and d.name.startswith(\"class_\")  # Enforce naming convention\n",
    "])\n",
    "\n",
    "print(f\"* No of Class Folders Found : {len(CLASS_NAMES)}\")\n",
    "print(\"* Detected class folders (sorted):\")\n",
    "for cls in CLASS_NAMES:\n",
    "    print(f\"  - {cls}\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 2: Create class-to-index mapping\n",
    "# ----------------------------------------------------------\n",
    "# Assign a unique integer label to each class name.\n",
    "# The index order is determined by the sorted CLASS_NAMES list.\n",
    "#\n",
    "# Example:\n",
    "#   class_0 -> 0\n",
    "#   class_1 -> 1\n",
    "# ----------------------------------------------------------\n",
    "CLASS_TO_IDX = {cls: idx for idx, cls in enumerate(CLASS_NAMES)}\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 3: Count total number of classes\n",
    "# ----------------------------------------------------------\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 4: Log final class mapping\n",
    "# ----------------------------------------------------------\n",
    "print(\"* Final class-to-index mapping:\")\n",
    "for class_name, class_idx in CLASS_TO_IDX.items():\n",
    "    print(f\"  - {class_name} â†’ {class_idx}\")\n",
    "\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(f\"* Total number of classes: {NUM_CLASSES}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a358024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¨ Initializing ImageNet preprocessing pipeline...\n",
      "ğŸ”„ Adding ToTensor():\n",
      "   - Converts NumPy/PIL image to torch.Tensor\n",
      "   - Reorders dimensions to (C, H, W)\n",
      "   - Scales pixel range to [0.0, 1.0]\n",
      "ğŸ“ Adding Normalize():\n",
      "   - Mean (RGB): [0.485, 0.456, 0.406]\n",
      "   - Std  (RGB): [0.229, 0.224, 0.225]\n",
      "ğŸ§© Composing preprocessing transforms\n",
      "âœ… ImageNet transform pipeline ready\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# VIDEO PREPROCESSING\n",
    "# ==========================================================\n",
    "\"\"\"\n",
    "- OpenCV used for video loading\n",
    "- Uniform frame sampling\n",
    "- Resize to 224Ã—224\n",
    "- ImageNet normalization (mandatory for pretrained models)\n",
    "\"\"\"\n",
    "\n",
    "# ==========================================================\n",
    "# IMAGENET PREPROCESSING TRANSFORM\n",
    "# ==========================================================\n",
    "# This transform prepares raw RGB image frames so they are\n",
    "# compatible with ImageNet-pretrained CNN backbones\n",
    "# (e.g., ResNet, EfficientNet).\n",
    "#\n",
    "# Expected input:\n",
    "#   - NumPy array or PIL Image\n",
    "#   - Shape: (H, W, C)\n",
    "#   - Value range: [0, 255]\n",
    "#\n",
    "# Output:\n",
    "#   - torch.Tensor\n",
    "#   - Shape: (C, H, W)\n",
    "#   - Normalized using ImageNet statistics\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\nğŸ¨ Initializing ImageNet preprocessing pipeline...\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 1: Convert image to PyTorch tensor\n",
    "# ----------------------------------------------------------\n",
    "# - Converts (H, W, C) â†’ (C, H, W)\n",
    "# - Scales pixel values from [0, 255] â†’ [0.0, 1.0]\n",
    "# ----------------------------------------------------------\n",
    "print(\"ğŸ”„ Adding ToTensor():\")\n",
    "print(\"   - Converts NumPy/PIL image to torch.Tensor\")\n",
    "print(\"   - Reorders dimensions to (C, H, W)\")\n",
    "print(\"   - Scales pixel range to [0.0, 1.0]\")\n",
    "\n",
    "to_tensor_transform = transforms.ToTensor()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 2: Normalize using ImageNet statistics\n",
    "# ----------------------------------------------------------\n",
    "# Normalization ensures that input distribution matches\n",
    "# what ImageNet-pretrained models were trained on.\n",
    "#\n",
    "# Channel order: RGB\n",
    "#\n",
    "# Formula per channel:\n",
    "#   normalized = (x - mean) / std\n",
    "# ----------------------------------------------------------\n",
    "print(\"ğŸ“ Adding Normalize():\")\n",
    "print(\"   - Mean (RGB): [0.485, 0.456, 0.406]\")\n",
    "print(\"   - Std  (RGB): [0.229, 0.224, 0.225]\")\n",
    "\n",
    "normalize_transform = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 3: Compose transforms into a single pipeline\n",
    "# ----------------------------------------------------------\n",
    "print(\"ğŸ§© Composing preprocessing transforms\")\n",
    "\n",
    "imagenet_transform = transforms.Compose([\n",
    "    to_tensor_transform,\n",
    "    normalize_transform\n",
    "])\n",
    "\n",
    "print(\"âœ… ImageNet transform pipeline ready\")\n",
    "\n",
    "\n",
    "def load_video(video_path, num_frames=NUM_FRAMES):\n",
    "    \"\"\"\n",
    "    Load a video file, extract frames, apply spatial preprocessing,\n",
    "    perform uniform temporal sampling, and return a tensor suitable\n",
    "    for deep learning models.\n",
    "\n",
    "    Args:\n",
    "        video_path (Path or str): Path to the video file.\n",
    "        num_frames (int): Number of frames to sample uniformly.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Video tensor of shape (T, C, H, W)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ğŸ¬ ==================================================\")\n",
    "    print(f\"ğŸ“ Video path      : {video_path}\")\n",
    "    print(f\"ğŸ§® Target #frames  : {num_frames}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 1: Open video using OpenCV\n",
    "    # --------------------------------------------------\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "    # Sanity check: ensure video file opened correctly\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"âŒ Failed to open video file: {video_path}\")\n",
    "\n",
    "    frames = []\n",
    "    frame_idx = 0\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 2: Read video frame-by-frame\n",
    "    # --------------------------------------------------\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # ret == False indicates end of video or read failure\n",
    "        if not ret:\n",
    "            # print(\"â¹ï¸  End of video reached or frame read failed\")\n",
    "            break\n",
    "\n",
    "        # Convert color space from OpenCV default (BGR) to RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize frame to match model input size\n",
    "        frame = cv2.resize(frame, IMG_SIZE)\n",
    "\n",
    "        frames.append(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "        # Periodic logging for long videos\n",
    "        # if frame_idx % 25 == 0:\n",
    "            # print(f\"  ğŸ“¸ Frames read so far: {frame_idx}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 3: Release video capture resource\n",
    "    # --------------------------------------------------\n",
    "    cap.release()\n",
    "    print(f\"âœ… Total frames extracted: {len(frames)}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 4: Uniform temporal sampling\n",
    "    # --------------------------------------------------\n",
    "    # Goal: Ensure exactly `num_frames` frames per video\n",
    "    # --------------------------------------------------\n",
    "    if len(frames) >= num_frames:\n",
    "        # print(\"ğŸ“ Applying uniform temporal sampling\")\n",
    "\n",
    "        # Generate evenly spaced indices across the full video\n",
    "        idx = np.linspace(\n",
    "            0,\n",
    "            len(frames) - 1,\n",
    "            num_frames\n",
    "        ).astype(int)\n",
    "\n",
    "        # print(f\"ğŸ”¢ Sampled frame indices: {idx.tolist()}\")\n",
    "\n",
    "        # Select frames at sampled indices\n",
    "        frames = [frames[i] for i in idx]\n",
    "    else:\n",
    "        print(\"âš ï¸  Video shorter than required frames\")\n",
    "        print(\"ğŸ” Padding by repeating last frame\")\n",
    "\n",
    "        # Repeat last frame until target length is reached\n",
    "        while len(frames) < num_frames:\n",
    "            frames.append(frames[-1])\n",
    "\n",
    "    print(f\"ğŸ§© Frames after temporal processing: {len(frames)}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 5: Apply ImageNet normalization / transforms\n",
    "    # --------------------------------------------------\n",
    "    # print(\"ğŸ¨ Applying ImageNet normalization & transforms\")\n",
    "\n",
    "    frames = [imagenet_transform(frame) for frame in frames]\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 6: Stack frames into a single tensor\n",
    "    # --------------------------------------------------\n",
    "    # Final shape: (T, C, H, W)\n",
    "    video_tensor = torch.stack(frames)\n",
    "\n",
    "    # print(\"ğŸ“¦ Final video tensor shape:\", video_tensor.shape)\n",
    "\n",
    "    return video_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba39f732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "ğŸ“‚ Loading TRAINING data\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "ğŸ“„ ==================================================\n",
      "ğŸ“„ Loading split file\n",
      "ğŸ“ Split file path: /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/splits/train.txt\n",
      "ğŸ“„ ==================================================\n",
      "ğŸ“‘ Total entries found in split file: 106\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 293\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 174\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g19_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g17_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 153\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g12_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 273\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g20_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 175\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c07.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 164\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 152\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 185\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g18_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 236\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 492\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g21_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g12_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 184\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 315\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g18_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 174\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g18_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 187\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g01_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 195\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 311\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g01_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 206\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g07_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 150\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 299\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 181\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g09_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 181\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g22_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 219\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g22_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 339\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g16_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g02_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g14_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 157\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g17_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 354\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g04_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 213\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g15_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g15_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g07_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g06_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 235\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 207\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g08_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 201\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g10_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g13_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 239\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g15_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 358\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g10_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g24_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 213\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g10_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g05_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 163\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g04_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g05_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g17_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 204\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g24_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 167\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g01_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g24_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 209\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g23_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 447\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g07_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 192\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 324\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g22_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 206\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g11_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 152\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g11_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 210\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g23_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 535\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g07_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 159\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g01_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g15_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g05_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g18_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g14_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g13_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 201\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g02_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 206\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g18_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g03_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 199\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g12_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 229\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g04_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g12_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g17_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g15_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g06_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 228\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g21_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g03_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g19_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 203\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g07_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 233\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g01_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g11_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g06_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g04_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g08_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c07.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g05_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g14_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g25_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "\n",
      "ğŸ“¦ Stacking videos and labels into tensors\n",
      "âœ… Split loaded successfully !! \n",
      "ğŸ“ Videos tensor shape: torch.Size([106, 16, 3, 224, 224])\n",
      "ğŸ·ï¸  Labels tensor shape: torch.Size([106])\n",
      "ğŸ“„ ==================================================\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "ğŸ“‚ Loading TESTING data\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "ğŸ“„ ==================================================\n",
      "ğŸ“„ Loading split file\n",
      "ğŸ“ Split file path: /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/splits/test.txt\n",
      "ğŸ“„ ==================================================\n",
      "ğŸ“‘ Total entries found in split file: 24\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 482\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g17_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 214\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 446\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g25_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 179\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 324\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g21_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 182\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g07_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 300\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 209\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 340\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g02_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 239\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g14_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 169\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g08_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g09_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 196\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g07_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g08_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 228\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 237\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g14_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 216\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g11_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 239\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g17_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g24_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g17_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "\n",
      "ğŸ“¦ Stacking videos and labels into tensors\n",
      "âœ… Split loaded successfully !! \n",
      "ğŸ“ Videos tensor shape: torch.Size([24, 16, 3, 224, 224])\n",
      "ğŸ·ï¸  Labels tensor shape: torch.Size([24])\n",
      "ğŸ“„ ==================================================\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "ğŸ“‚ Loading VALIDATION data\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "ğŸ“„ ==================================================\n",
      "ğŸ“„ Loading split file\n",
      "ğŸ“ Split file path: /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/splits/val.txt\n",
      "ğŸ“„ ==================================================\n",
      "ğŸ“‘ Total entries found in split file: 22\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g12_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 230\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g08_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 171\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g25_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g12_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 228\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 336\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g02_c07.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g12_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 201\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g25_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g11_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g04_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g17_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g24_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g22_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g02_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g10_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g02_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g03_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g11_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ“ Video path      : /home/jovyan/va-volume/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g22_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "\n",
      "ğŸ“¦ Stacking videos and labels into tensors\n",
      "âœ… Split loaded successfully !! \n",
      "ğŸ“ Videos tensor shape: torch.Size([22, 16, 3, 224, 224])\n",
      "ğŸ·ï¸  Labels tensor shape: torch.Size([22])\n",
      "ğŸ“„ ==================================================\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "âœ… Dataset summary\n",
      "-----------------------------------------------\n",
      "\n",
      "ğŸ“ Training videos    : 106\n",
      "ğŸ§ª Testing videos     : 24\n",
      "ğŸ§ª Validation videos  : 22\n",
      "ğŸ·ï¸  Total classes     : 3\n",
      "ğŸ“ Train tensor       : torch.Size([106, 16, 3, 224, 224])  (N, T, C, H, W)\n",
      "ğŸ“ Test tensor        : torch.Size([24, 16, 3, 224, 224])   (N, T, C, H, W)\n",
      "ğŸ“ Validation tensor  : torch.Size([22, 16, 3, 224, 224])   (N, T, C, H, W)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# LOAD DATA USING OFFICIAL TRAIN / TEST SPLITS\n",
    "# ==========================================================\n",
    "# This section loads videos and labels using pre-defined\n",
    "# split files (e.g., train.txt, test.txt).\n",
    "#\n",
    "# Each split file is expected to contain relative paths\n",
    "# to video files, one per line, such as:\n",
    "#\n",
    "#   class_0/video_001.avi\n",
    "#   class_1/video_023.avi\n",
    "#\n",
    "# The parent folder name (class_*) is used as the label.\n",
    "# ==========================================================\n",
    "\n",
    "def load_split(split_file):\n",
    "    \"\"\"\n",
    "    Load videos and labels from a split file.\n",
    "\n",
    "    Args:\n",
    "        split_file (Path): Path to the split text file.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]:\n",
    "            - videos: Tensor of shape (N, T, C, H, W)\n",
    "            - labels: Tensor of shape (N,)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nğŸ“„ ==================================================\")\n",
    "    print(\"ğŸ“„ Loading split file\")\n",
    "    print(f\"ğŸ“ Split file path: {split_file}\")\n",
    "    print(\"ğŸ“„ ==================================================\")\n",
    "\n",
    "    videos = []  # Will store per-video tensors\n",
    "    labels = []  # Will store integer class labels\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 1: Read split file\n",
    "    # --------------------------------------------------\n",
    "    with open(split_file, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    print(f\"ğŸ“‘ Total entries found in split file: {len(lines)}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 2: Process each video entry\n",
    "    # --------------------------------------------------\n",
    "    for idx, line in enumerate(lines):\n",
    "        # Construct absolute video path\n",
    "        video_path = DATASET_ROOT / line\n",
    "\n",
    "        # Extract class name from path\n",
    "        # Example: \"class_2/video_003.avi\" â†’ \"class_2\"\n",
    "        class_name = line.split(\"/\")[0]\n",
    "\n",
    "        # Map class name to integer label\n",
    "        label = CLASS_TO_IDX[class_name]\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ¬ ----------------------------------------------\")\n",
    "        print(f\"ğŸ¥ Processing video {idx + 1}/{len(lines)}\")\n",
    "        print(f\"ğŸ“ Relative path : {line}\")\n",
    "        print(f\"ğŸ“ Absolute path : {video_path}\")\n",
    "        print(f\"ğŸ·ï¸  Class name   : {class_name}\")\n",
    "        print(f\"ğŸ”¢ Class index  : {label}\")\n",
    "        print(\"ğŸ¬ ----------------------------------------------\")\n",
    "        \"\"\"\n",
    "\n",
    "        # Load and preprocess video (T, C, H, W)\n",
    "        video_tensor = load_video(video_path)\n",
    "\n",
    "        # Append video tensor and label\n",
    "        videos.append(video_tensor)\n",
    "        labels.append(label)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 3: Stack videos and labels into tensors\n",
    "    # --------------------------------------------------\n",
    "    print(\"\\nğŸ“¦ Stacking videos and labels into tensors\")\n",
    "\n",
    "    videos_tensor = torch.stack(videos)        # Shape: (N, T, C, H, W)\n",
    "    labels_tensor = torch.tensor(labels)       # Shape: (N,)\n",
    "\n",
    "    print(\"âœ… Split loaded successfully !! \")\n",
    "    print(f\"ğŸ“ Videos tensor shape: {videos_tensor.shape}\")\n",
    "    print(f\"ğŸ·ï¸  Labels tensor shape: {labels_tensor.shape}\")\n",
    "    print(\"ğŸ“„ ==================================================\\n\")\n",
    "\n",
    "    return videos_tensor, labels_tensor\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD TRAINING DATA\n",
    "# ==========================================================\n",
    "print(\"\\n-----------------------------------------------\")\n",
    "print(\"ğŸ“‚ Loading TRAINING data\")\n",
    "print(\"-----------------------------------------------\\n\")\n",
    "\n",
    "X_train, y_train = load_split(SPLITS_DIR / \"train.txt\")\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD TESTING DATA\n",
    "# ==========================================================\n",
    "print(\"\\n-----------------------------------------------\")\n",
    "print(\"ğŸ“‚ Loading TESTING data\")\n",
    "print(\"-----------------------------------------------\\n\")\n",
    "\n",
    "X_test, y_test = load_split(SPLITS_DIR / \"test.txt\")\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD VALIDATION DATA\n",
    "# ==========================================================\n",
    "print(\"\\n-----------------------------------------------\")\n",
    "print(\"ğŸ“‚ Loading VALIDATION data\")\n",
    "print(\"-----------------------------------------------\\n\")\n",
    "\n",
    "X_val, y_val = load_split(SPLITS_DIR / \"val.txt\")\n",
    "\n",
    "# ==========================================================\n",
    "# DATASET SUMMARY\n",
    "# ==========================================================\n",
    "print(\"\\n-----------------------------------------------\")\n",
    "print(\"âœ… Dataset summary\")\n",
    "print(\"-----------------------------------------------\\n\")\n",
    "\n",
    "print(f\"ğŸ“ Training videos    : {len(X_train)}\")\n",
    "print(f\"ğŸ§ª Testing videos     : {len(X_test)}\")\n",
    "print(f\"ğŸ§ª Validation videos  : {len(X_val)}\")\n",
    "print(f\"ğŸ·ï¸  Total classes     : {NUM_CLASSES}\")\n",
    "print(f\"ğŸ“ Train tensor       : {X_train.shape}  (N, T, C, H, W)\")\n",
    "print(f\"ğŸ“ Test tensor        : {X_test.shape}   (N, T, C, H, W)\")\n",
    "print(f\"ğŸ“ Validation tensor  : {X_val.shape}   (N, T, C, H, W)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57ca61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# VIDEO DATASET WITH OPTIONAL DATA AUGMENTATION\n",
    "# ==========================================================\n",
    "class VideoDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for video classification.\n",
    "\n",
    "    Each sample consists of:\n",
    "    - A video: sequence of frames (Tensor)\n",
    "    - A label: class index or class name\n",
    "\n",
    "    Data augmentation:\n",
    "    - Random horizontal flip is applied\n",
    "      ONLY when train=True\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: List[torch.Tensor],\n",
    "        y: List[int],\n",
    "        train: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "\n",
    "        Args:\n",
    "            X (List[Tensor]):\n",
    "                List of videos.\n",
    "                Each video is a Tensor of shape:\n",
    "                (num_frames, channels, height, width)\n",
    "\n",
    "            y (List[int]):\n",
    "                Corresponding labels for each video.\n",
    "\n",
    "            train (bool):\n",
    "                If True:\n",
    "                    - Apply data augmentation (horizontal flip)\n",
    "                If False:\n",
    "                    - No augmentation (used for validation/testing)\n",
    "        \"\"\"\n",
    "        # Store videos\n",
    "        self.X = X\n",
    "\n",
    "        # Store labels\n",
    "        self.y = y\n",
    "\n",
    "        # Flag to control augmentation behavior\n",
    "        self.train = train\n",
    "\n",
    "        # Define spatial augmentation:\n",
    "        # Randomly flips an image horizontally with 50% probability\n",
    "        #\n",
    "        # IMPORTANT:\n",
    "        # - This does NOT add new pixels\n",
    "        # - It only rearranges existing pixels\n",
    "        self.flip = transforms.RandomHorizontalFlip(p=0.5)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Return the total number of samples in the dataset.\n",
    "\n",
    "        This method is required by PyTorch's Dataset class\n",
    "        so that DataLoader knows how many samples exist.\n",
    "        \"\"\"\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"\"\"\n",
    "        Retrieve one sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int):\n",
    "                Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, int]:\n",
    "                - video: Tensor of shape\n",
    "                  (num_frames, channels, height, width)\n",
    "                - label: corresponding class label\n",
    "        \"\"\"\n",
    "        # Fetch the video at the given index\n",
    "        video = self.X[idx]\n",
    "\n",
    "        # Apply data augmentation ONLY during training\n",
    "        if self.train:\n",
    "            # Apply horizontal flip independently to each frame\n",
    "            #\n",
    "            # Why per-frame?\n",
    "            # - Each frame is treated as an image\n",
    "            # - Maintains temporal order\n",
    "            # - Simple and effective spatial augmentation\n",
    "            #\n",
    "            # torch.stack is used to reconstruct the video\n",
    "            # back into a single Tensor\n",
    "            video = torch.stack([self.flip(frame) for frame in video])\n",
    "\n",
    "        # Return video and its label\n",
    "        return video, self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0eaf95e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Training - Data loaders initialized successfully !!\n",
      "\n",
      "âœ… Testing - Data loaders initialized successfully !!\n",
      "\n",
      "âœ… Validation - Data loaders initialized successfully !!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# DATALOADERS\n",
    "# ==========================================================\n",
    "train_loader = DataLoader(\n",
    "    VideoDataset(X_train, y_train, train=True),\n",
    "    batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training - Data loaders initialized successfully !!\")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    VideoDataset(X_test, y_test, train=False),\n",
    "    batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Testing - Data loaders initialized successfully !!\")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    VideoDataset(X_val, y_val, train=False),\n",
    "    batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Validation - Data loaders initialized successfully !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af423aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# TRAINING & EVALUATION FUNCTION\n",
    "# ==========================================================\n",
    "def train_and_evaluate(model, model_name):\n",
    "    \"\"\"\n",
    "    Train a deep learning model and evaluate its performance\n",
    "    with early stopping and regularization.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Create directory structure for storing results\n",
    "    # ------------------------------------------------------\n",
    "    base_dir = PROJECT_ROOT / \"results\"\n",
    "    cm_dir = base_dir / \"confusion_matrices\"\n",
    "    perf_dir = base_dir / \"performance_plots\"\n",
    "    feat_dir = base_dir / \"feature_visualizations\"\n",
    "\n",
    "    cm_dir.mkdir(parents=True, exist_ok=True)\n",
    "    perf_dir.mkdir(parents=True, exist_ok=True)\n",
    "    feat_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Model setup\n",
    "    # ------------------------------------------------------\n",
    "    print(f\"\\nğŸš€ Training {model_name}\")\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Optimizer, Loss, Scheduler\n",
    "    # ------------------------------------------------------\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=1e-4  # L2 regularization\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=EPOCHS\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Early Stopping\n",
    "    # ------------------------------------------------------\n",
    "    class EarlyStopping:\n",
    "        def __init__(self, patience=5, min_delta=1e-4):\n",
    "            self.patience = patience\n",
    "            self.min_delta = min_delta\n",
    "            self.best_loss = float(\"inf\")\n",
    "            self.counter = 0\n",
    "            self.should_stop = False\n",
    "\n",
    "        def step(self, val_loss):\n",
    "            if val_loss < self.best_loss - self.min_delta:\n",
    "                self.best_loss = val_loss\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.patience:\n",
    "                    self.should_stop = True\n",
    "\n",
    "    early_stopper = EarlyStopping(patience=5)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Training loop\n",
    "    # ------------------------------------------------------\n",
    "    start_train = time.time()\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        # ------------------ TRAIN ------------------\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for videos, labels in train_loader:\n",
    "            videos = videos.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(videos)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        epoch_losses.append(train_loss)\n",
    "\n",
    "        # ------------------ VALIDATION ------------------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for videos, labels in val_loader:\n",
    "                videos = videos.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                outputs = model(videos)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "        # ------------------ Early Stopping ------------------\n",
    "        early_stopper.step(val_loss)\n",
    "        if early_stopper.should_stop:\n",
    "            print(f\"â¹ Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    train_time = time.time() - start_train\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Save training loss curve\n",
    "    # ------------------------------------------------------\n",
    "    plt.figure()\n",
    "    plt.plot(epoch_losses, marker=\"o\")\n",
    "    plt.title(f\"{model_name} - Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    loss_plot_path = perf_dir / f\"{model_name.replace(' ', '_')}_loss.png\"\n",
    "    plt.savefig(loss_plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Evaluation (Test Set)\n",
    "    # ------------------------------------------------------\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "\n",
    "    start_inf = time.time()\n",
    "    with torch.no_grad():\n",
    "        for videos, labels in test_loader:\n",
    "            videos = videos.to(DEVICE)\n",
    "            outputs = model(videos)\n",
    "            batch_preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            preds.extend(batch_preds.cpu().numpy())\n",
    "            targets.extend(labels.numpy())\n",
    "\n",
    "    inf_time = (time.time() - start_inf) / len(targets)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Metrics\n",
    "    # ------------------------------------------------------\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(targets, preds),\n",
    "        \"precision\": precision_score(targets, preds, average=\"macro\"),\n",
    "        \"recall\": recall_score(targets, preds, average=\"macro\"),\n",
    "        \"f1\": f1_score(targets, preds, average=\"macro\"),\n",
    "        \"train_time\": train_time,\n",
    "        \"inf_time\": inf_time,\n",
    "        \"cm\": confusion_matrix(targets, preds)\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Reporting\n",
    "    # ------------------------------------------------------\n",
    "    print(f\"\\nğŸ“Š {model_name} Performance\")\n",
    "    for k, v in metrics.items():\n",
    "        if k != \"cm\":\n",
    "            print(f\"{k.replace('_', ' ').title():<20}: {v:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(metrics[\"cm\"], annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"{model_name} - Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cm_path = cm_dir / f\"{model_name.replace(' ', '_')}_cm.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe317536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training 2D CNN + Temporal Pooling\n",
      "Epoch [1/5] | Train Loss: 0.8681 | Val Loss: 0.2631\n",
      "Epoch [2/5] | Train Loss: 0.3648 | Val Loss: 0.1858\n",
      "Epoch [3/5] | Train Loss: 0.3437 | Val Loss: 0.1547\n",
      "Epoch [4/5] | Train Loss: 0.1455 | Val Loss: 0.1901\n",
      "Epoch [5/5] | Train Loss: 0.2320 | Val Loss: 0.1954\n",
      "\n",
      "ğŸ“Š 2D CNN + Temporal Pooling Performance\n",
      "Accuracy            : 1.0000\n",
      "Precision           : 1.0000\n",
      "Recall              : 1.0000\n",
      "F1                  : 1.0000\n",
      "Train Time          : 11.4178\n",
      "Inf Time            : 0.0121\n",
      "\n",
      "ğŸš€ Training 3D CNN (R(2+1)D)\n",
      "Epoch [1/5] | Train Loss: 0.9899 | Val Loss: 0.3507\n",
      "Epoch [2/5] | Train Loss: 0.2559 | Val Loss: 0.1987\n",
      "Epoch [3/5] | Train Loss: 0.2539 | Val Loss: 0.1036\n",
      "Epoch [4/5] | Train Loss: 0.2564 | Val Loss: 0.0803\n",
      "Epoch [5/5] | Train Loss: 0.2668 | Val Loss: 0.0805\n",
      "\n",
      "ğŸ“Š 3D CNN (R(2+1)D) Performance\n",
      "Accuracy            : 1.0000\n",
      "Precision           : 1.0000\n",
      "Recall              : 1.0000\n",
      "F1                  : 1.0000\n",
      "Train Time          : 70.7867\n",
      "Inf Time            : 0.0193\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# RUN EXPERIMENTS\n",
    "# ==========================================================\n",
    "\n",
    "metrics_2d = train_and_evaluate(\n",
    "    CNN2DTemporal(NUM_CLASSES),\n",
    "    \"2D CNN + Temporal Pooling\"\n",
    ")\n",
    "\n",
    "metrics_3d = train_and_evaluate(\n",
    "    CNN3D(NUM_CLASSES),\n",
    "    \"3D CNN (R(2+1)D)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebb1a942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“ˆ DETAILED MODEL COMPARISON REPORT\n",
      "============================================================\n",
      "\n",
      "ğŸ”¹ Accuracy Comparison\n",
      "2D CNN Accuracy : 1.0000\n",
      "3D CNN Accuracy : 1.0000\n",
      "\n",
      "ğŸ”¹ Computational Efficiency\n",
      "2D CNN Training Time (s)        : 11.42\n",
      "3D CNN Training Time (s)        : 70.79\n",
      "2D CNN Inference Time / Video(s): 0.0121\n",
      "3D CNN Inference Time / Video(s): 0.0193\n",
      "\n",
      "ğŸ”¹ Qualitative Analysis\n",
      "âœ” The 2D CNN achieves competitive accuracy with significantly lower computational cost, making it suitable for real-time applications.\n",
      "\n",
      "ğŸ”¹ Final Conclusion:\n",
      "2D CNNs provide a strong baseline with efficient inference, while 3D CNNs offer improved performance at the cost of higher computation.\n",
      "\n",
      "âœ… Experiment completed successfully\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# DETAILED COMPARISON REPORT\n",
    "# ==========================================================\n",
    "\n",
    "def compare_models(metrics_2d, metrics_3d):\n",
    "    \"\"\"\n",
    "    Generate comparison charts and a detailed report\n",
    "    for 2D CNN vs 3D CNN models.\n",
    "\n",
    "    Args:\n",
    "        metrics_2d (dict): Metrics for 2D CNN\n",
    "        metrics_3d (dict): Metrics for 3D CNN\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Sanity checks\n",
    "    # ------------------------------------------------------\n",
    "    required_keys = {\"accuracy\", \"train_time\", \"inf_time\"}\n",
    "\n",
    "    if not required_keys.issubset(metrics_2d):\n",
    "        raise ValueError(\"metrics_2d missing required keys\")\n",
    "\n",
    "    if not required_keys.issubset(metrics_3d):\n",
    "        raise ValueError(\"metrics_3d missing required keys\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Extract metrics\n",
    "    # ------------------------------------------------------\n",
    "    models = [\"2D CNN\", \"3D CNN\"]\n",
    "\n",
    "    accuracy = [\n",
    "        metrics_2d[\"accuracy\"],\n",
    "        metrics_3d[\"accuracy\"]\n",
    "    ]\n",
    "\n",
    "    train_time = [\n",
    "        metrics_2d[\"train_time\"],\n",
    "        metrics_3d[\"train_time\"]\n",
    "    ]\n",
    "\n",
    "    inf_time = [\n",
    "        metrics_2d[\"inf_time\"],\n",
    "        metrics_3d[\"inf_time\"]\n",
    "    ]\n",
    "\n",
    "    # ======================================================\n",
    "    # CHART 1: Accuracy Comparison\n",
    "    # ======================================================\n",
    "    plt.figure()\n",
    "    plt.bar(models, accuracy)\n",
    "    plt.title(\"Model Accuracy Comparison\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "    # ======================================================\n",
    "    # CHART 2: Training Time Comparison\n",
    "    # ======================================================\n",
    "    plt.figure()\n",
    "    plt.bar(models, train_time)\n",
    "    plt.title(\"Training Time Comparison\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ======================================================\n",
    "    # CHART 3: Inference Time Comparison\n",
    "    # ======================================================\n",
    "    plt.figure()\n",
    "    plt.bar(models, inf_time)\n",
    "    plt.title(\"Inference Time per Video Comparison\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ======================================================\n",
    "    # TEXTUAL COMPARISON REPORT\n",
    "    # ======================================================\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“ˆ DETAILED MODEL COMPARISON REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Accuracy\n",
    "    print(\"\\nğŸ”¹ Accuracy Comparison\")\n",
    "    print(f\"2D CNN Accuracy : {metrics_2d['accuracy']:.4f}\")\n",
    "    print(f\"3D CNN Accuracy : {metrics_3d['accuracy']:.4f}\")\n",
    "\n",
    "    # Efficiency\n",
    "    print(\"\\nğŸ”¹ Computational Efficiency\")\n",
    "    print(f\"2D CNN Training Time (s)        : {metrics_2d['train_time']:.2f}\")\n",
    "    print(f\"3D CNN Training Time (s)        : {metrics_3d['train_time']:.2f}\")\n",
    "    print(f\"2D CNN Inference Time / Video(s): {metrics_2d['inf_time']:.4f}\")\n",
    "    print(f\"3D CNN Inference Time / Video(s): {metrics_3d['inf_time']:.4f}\")\n",
    "\n",
    "    # Qualitative analysis\n",
    "    print(\"\\nğŸ”¹ Qualitative Analysis\")\n",
    "    if metrics_3d[\"accuracy\"] > metrics_2d[\"accuracy\"]:\n",
    "        print(\n",
    "            \"âœ” The 3D CNN outperforms the 2D CNN by explicitly modeling \"\n",
    "            \"spatiotemporal patterns, making it more suitable for complex actions.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"âœ” The 2D CNN achieves competitive accuracy with significantly lower \"\n",
    "            \"computational cost, making it suitable for real-time applications.\"\n",
    "        )\n",
    "\n",
    "    # Final conclusion\n",
    "    print(\n",
    "        \"\\nğŸ”¹ Final Conclusion:\\n\"\n",
    "        \"2D CNNs provide a strong baseline with efficient inference, while \"\n",
    "        \"3D CNNs offer improved performance at the cost of higher computation.\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nâœ… Experiment completed successfully\")\n",
    "\n",
    "compare_models(metrics_2d, metrics_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699bd8d3-145d-4563-add2-edb0e37b0bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
