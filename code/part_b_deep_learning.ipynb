{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa53da25",
   "metadata": {},
   "source": [
    "PART B: DEEP LEARNING VIDEO CLASSIFICATION (REAL DATA)\n",
    "\n",
    "This script implements:\n",
    "1. 2D CNN (ResNet-18) + Temporal Pooling\n",
    "2. 3D CNN (R(2+1)D-18)\n",
    "\n",
    "Dataset:\n",
    "- UCF-style directory\n",
    "- Predefined train/test splits\n",
    "\n",
    "Evaluation:\n",
    "- Accuracy\n",
    "- Precision (macro)\n",
    "- Recall (macro)\n",
    "- F1-score (macro)\n",
    "- Confusion Matrix\n",
    "- Training time\n",
    "- Inference time per video\n",
    "\n",
    "Author: 2024ab05275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7155a69f-1727-4343-8b54-45bfac7cbf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.10 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.11.3)\n",
      "Requirement already satisfied: torch>=2.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (2.3.0+cu121)\n",
      "Requirement already satisfied: torchvision>=0.15 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.18.0+cu121)\n",
      "Collecting opencv-python-headless (from -r requirements.txt (line 10))\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.3 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.22.0)\n",
      "Requirement already satisfied: matplotlib>=3.7 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (3.8.4)\n",
      "Requirement already satisfied: seaborn>=0.13 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.66 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (4.66.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->-r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.15->-r requirements.txt (line 7)) (10.4.0)\n",
      "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.3->-r requirements.txt (line 11)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.3->-r requirements.txt (line 11)) (3.5.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 12)) (2.34.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 12)) (2024.7.2)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 12)) (24.1)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.11/site-packages (from scikit-image->-r requirements.txt (line 12)) (0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7->-r requirements.txt (line 15)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7->-r requirements.txt (line 15)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7->-r requirements.txt (line 15)) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7->-r requirements.txt (line 15)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7->-r requirements.txt (line 15)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7->-r requirements.txt (line 15)) (2.9.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.11/site-packages (from seaborn>=0.13->-r requirements.txt (line 16)) (2.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn>=0.13->-r requirements.txt (line 16)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn>=0.13->-r requirements.txt (line 16)) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.7->-r requirements.txt (line 15)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0->-r requirements.txt (line 6)) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.0->-r requirements.txt (line 6)) (1.3.0)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf86cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# IMPORTS\n",
    "# ==========================================================\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df9008d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "âœ… Project root: /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification\n",
      "âœ… Dataset root: /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset\n",
      "----------------------------------------------------------\n",
      "ğŸš€ Running on device: cuda\n",
      "----------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# CONFIGURATION\n",
    "# ==========================================================\n",
    "# Current file is inside /code\n",
    "CODE_DIR = Path.cwd()\n",
    "\n",
    "# Project root is one level above\n",
    "PROJECT_ROOT = CODE_DIR.parent\n",
    "\n",
    "DATASET_ROOT = PROJECT_ROOT / \"dataset\"\n",
    "SPLITS_DIR = DATASET_ROOT / \"splits\"\n",
    "\n",
    "LOCAL_WEIGHTS = os.path.join(PROJECT_ROOT, \"model\", \"resnet18-f37072fd.pth\")\n",
    "\n",
    "# Safety checks (VERY IMPORTANT)\n",
    "assert DATASET_ROOT.exists(), f\"Dataset not found at {DATASET_ROOT}\"\n",
    "assert SPLITS_DIR.exists(), f\"Splits folder not found at {SPLITS_DIR}\"\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(f\"âœ… Project root: {PROJECT_ROOT}\")\n",
    "print(f\"âœ… Dataset root: {DATASET_ROOT}\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "NUM_FRAMES = 16                 # Frames sampled per video\n",
    "IMG_SIZE = (224, 224)           # Required for pretrained CNNs\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸš€ Running on device: {DEVICE}\")\n",
    "print(\"----------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73aa49f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Scanning dataset root for class folders.....\n",
      "* Dataset root path: /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset\n",
      "----------------------------------------------------------\n",
      "* No of Class Folders Found : 3\n",
      "* Detected class folders (sorted):\n",
      "  - class_1_Basketball\n",
      "  - class_2_Biking\n",
      "  - class_3_WalkingWithDog\n",
      "----------------------------------------------------------\n",
      "* Final class-to-index mapping:\n",
      "  - class_1_Basketball â†’ 0\n",
      "  - class_2_Biking â†’ 1\n",
      "  - class_3_WalkingWithDog â†’ 2\n",
      "----------------------------------------------------------\n",
      "* Total number of classes: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# CLASS MAPPING (Derived from dataset folder names)\n",
    "# ==========================================================\n",
    "# This section automatically discovers class labels from the\n",
    "# dataset directory structure.\n",
    "#\n",
    "# Expected directory format:\n",
    "# DATASET_ROOT/\n",
    "# â”œâ”€â”€ class_0/\n",
    "# â”œâ”€â”€ class_1/\n",
    "# â”œâ”€â”€ class_2/\n",
    "# â””â”€â”€ ...\n",
    "#\n",
    "# Each \"class_*\" folder represents one target class.\n",
    "# ==========================================================\n",
    "\n",
    "print(\"* Scanning dataset root for class folders.....\")\n",
    "print(f\"* Dataset root path: {DATASET_ROOT}\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "# ----------------------------------------------------------\n",
    "# Step 1: Discover class directory names\n",
    "# ----------------------------------------------------------\n",
    "# - Iterate over all items inside DATASET_ROOT\n",
    "# - Keep only directories\n",
    "# - Keep only directory names that start with \"class_\"\n",
    "# - Sort them to ensure consistent class index assignment\n",
    "# ----------------------------------------------------------\n",
    "CLASS_NAMES = sorted([\n",
    "    d.name                      # Folder name (e.g., \"class_1\")\n",
    "    for d in DATASET_ROOT.iterdir()\n",
    "    if d.is_dir()                # Ensure it is a directory\n",
    "    and d.name.startswith(\"class_\")  # Enforce naming convention\n",
    "])\n",
    "\n",
    "print(f\"* No of Class Folders Found : {len(CLASS_NAMES)}\")\n",
    "print(\"* Detected class folders (sorted):\")\n",
    "for cls in CLASS_NAMES:\n",
    "    print(f\"  - {cls}\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 2: Create class-to-index mapping\n",
    "# ----------------------------------------------------------\n",
    "# Assign a unique integer label to each class name.\n",
    "# The index order is determined by the sorted CLASS_NAMES list.\n",
    "#\n",
    "# Example:\n",
    "#   class_0 -> 0\n",
    "#   class_1 -> 1\n",
    "# ----------------------------------------------------------\n",
    "CLASS_TO_IDX = {cls: idx for idx, cls in enumerate(CLASS_NAMES)}\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 3: Count total number of classes\n",
    "# ----------------------------------------------------------\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 4: Log final class mapping\n",
    "# ----------------------------------------------------------\n",
    "print(\"* Final class-to-index mapping:\")\n",
    "for class_name, class_idx in CLASS_TO_IDX.items():\n",
    "    print(f\"  - {class_name} â†’ {class_idx}\")\n",
    "\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(f\"* Total number of classes: {NUM_CLASSES}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a358024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¨ Initializing ImageNet preprocessing pipeline...\n",
      "ğŸ”„ Adding ToTensor():\n",
      "   - Converts NumPy/PIL image to torch.Tensor\n",
      "   - Reorders dimensions to (C, H, W)\n",
      "   - Scales pixel range to [0.0, 1.0]\n",
      "ğŸ“ Adding Normalize():\n",
      "   - Mean (RGB): [0.485, 0.456, 0.406]\n",
      "   - Std  (RGB): [0.229, 0.224, 0.225]\n",
      "ğŸ§© Composing preprocessing transforms\n",
      "âœ… ImageNet transform pipeline ready\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# VIDEO PREPROCESSING\n",
    "# ==========================================================\n",
    "\"\"\"\n",
    "- OpenCV used for video loading\n",
    "- Uniform frame sampling\n",
    "- Resize to 224Ã—224\n",
    "- ImageNet normalization (mandatory for pretrained models)\n",
    "\"\"\"\n",
    "\n",
    "# ==========================================================\n",
    "# IMAGENET PREPROCESSING TRANSFORM\n",
    "# ==========================================================\n",
    "# This transform prepares raw RGB image frames so they are\n",
    "# compatible with ImageNet-pretrained CNN backbones\n",
    "# (e.g., ResNet, EfficientNet).\n",
    "#\n",
    "# Expected input:\n",
    "#   - NumPy array or PIL Image\n",
    "#   - Shape: (H, W, C)\n",
    "#   - Value range: [0, 255]\n",
    "#\n",
    "# Output:\n",
    "#   - torch.Tensor\n",
    "#   - Shape: (C, H, W)\n",
    "#   - Normalized using ImageNet statistics\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\nğŸ¨ Initializing ImageNet preprocessing pipeline...\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 1: Convert image to PyTorch tensor\n",
    "# ----------------------------------------------------------\n",
    "# - Converts (H, W, C) â†’ (C, H, W)\n",
    "# - Scales pixel values from [0, 255] â†’ [0.0, 1.0]\n",
    "# ----------------------------------------------------------\n",
    "print(\"ğŸ”„ Adding ToTensor():\")\n",
    "print(\"   - Converts NumPy/PIL image to torch.Tensor\")\n",
    "print(\"   - Reorders dimensions to (C, H, W)\")\n",
    "print(\"   - Scales pixel range to [0.0, 1.0]\")\n",
    "\n",
    "to_tensor_transform = transforms.ToTensor()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 2: Normalize using ImageNet statistics\n",
    "# ----------------------------------------------------------\n",
    "# Normalization ensures that input distribution matches\n",
    "# what ImageNet-pretrained models were trained on.\n",
    "#\n",
    "# Channel order: RGB\n",
    "#\n",
    "# Formula per channel:\n",
    "#   normalized = (x - mean) / std\n",
    "# ----------------------------------------------------------\n",
    "print(\"ğŸ“ Adding Normalize():\")\n",
    "print(\"   - Mean (RGB): [0.485, 0.456, 0.406]\")\n",
    "print(\"   - Std  (RGB): [0.229, 0.224, 0.225]\")\n",
    "\n",
    "normalize_transform = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 3: Compose transforms into a single pipeline\n",
    "# ----------------------------------------------------------\n",
    "print(\"ğŸ§© Composing preprocessing transforms\")\n",
    "\n",
    "imagenet_transform = transforms.Compose([\n",
    "    to_tensor_transform,\n",
    "    normalize_transform\n",
    "])\n",
    "\n",
    "print(\"âœ… ImageNet transform pipeline ready\")\n",
    "\n",
    "\n",
    "def load_video(video_path, num_frames=NUM_FRAMES):\n",
    "    \"\"\"\n",
    "    Load a video file, extract frames, apply spatial preprocessing,\n",
    "    perform uniform temporal sampling, and return a tensor suitable\n",
    "    for deep learning models.\n",
    "\n",
    "    Args:\n",
    "        video_path (Path or str): Path to the video file.\n",
    "        num_frames (int): Number of frames to sample uniformly.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Video tensor of shape (T, C, H, W)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nğŸ¬ ==================================================\")\n",
    "    print(\"ğŸ¥ Loading video\")\n",
    "    print(f\"ğŸ“ Video path      : {video_path}\")\n",
    "    print(f\"ğŸ§® Target #frames  : {num_frames}\")\n",
    "    print(\"ğŸ¬ ==================================================\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 1: Open video using OpenCV\n",
    "    # --------------------------------------------------\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "    # Sanity check: ensure video file opened correctly\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"âŒ Failed to open video file: {video_path}\")\n",
    "\n",
    "    frames = []\n",
    "    frame_idx = 0\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 2: Read video frame-by-frame\n",
    "    # --------------------------------------------------\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # ret == False indicates end of video or read failure\n",
    "        if not ret:\n",
    "            print(\"â¹ï¸  End of video reached or frame read failed\")\n",
    "            break\n",
    "\n",
    "        # Convert color space from OpenCV default (BGR) to RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize frame to match model input size\n",
    "        frame = cv2.resize(frame, IMG_SIZE)\n",
    "\n",
    "        frames.append(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "        # Periodic logging for long videos\n",
    "        if frame_idx % 25 == 0:\n",
    "            print(f\"  ğŸ“¸ Frames read so far: {frame_idx}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 3: Release video capture resource\n",
    "    # --------------------------------------------------\n",
    "    cap.release()\n",
    "    print(f\"âœ… Total frames extracted: {len(frames)}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 4: Uniform temporal sampling\n",
    "    # --------------------------------------------------\n",
    "    # Goal: Ensure exactly `num_frames` frames per video\n",
    "    # --------------------------------------------------\n",
    "    if len(frames) >= num_frames:\n",
    "        print(\"ğŸ“ Applying uniform temporal sampling\")\n",
    "\n",
    "        # Generate evenly spaced indices across the full video\n",
    "        idx = np.linspace(\n",
    "            0,\n",
    "            len(frames) - 1,\n",
    "            num_frames\n",
    "        ).astype(int)\n",
    "\n",
    "        print(f\"ğŸ”¢ Sampled frame indices: {idx.tolist()}\")\n",
    "\n",
    "        # Select frames at sampled indices\n",
    "        frames = [frames[i] for i in idx]\n",
    "    else:\n",
    "        print(\"âš ï¸  Video shorter than required frames\")\n",
    "        print(\"ğŸ” Padding by repeating last frame\")\n",
    "\n",
    "        # Repeat last frame until target length is reached\n",
    "        while len(frames) < num_frames:\n",
    "            frames.append(frames[-1])\n",
    "\n",
    "    print(f\"ğŸ§© Frames after temporal processing: {len(frames)}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 5: Apply ImageNet normalization / transforms\n",
    "    # --------------------------------------------------\n",
    "    print(\"ğŸ¨ Applying ImageNet normalization & transforms\")\n",
    "\n",
    "    frames = [imagenet_transform(frame) for frame in frames]\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 6: Stack frames into a single tensor\n",
    "    # --------------------------------------------------\n",
    "    # Final shape: (T, C, H, W)\n",
    "    video_tensor = torch.stack(frames)\n",
    "\n",
    "    print(\"ğŸ“¦ Final video tensor shape:\", video_tensor.shape)\n",
    "    print(\"ğŸ¬ ==================================================\\n\")\n",
    "\n",
    "    return video_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba39f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "ğŸ“‚ Loading TRAINING data\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "ğŸ“„ ==================================================\n",
      "ğŸ“„ Loading split file\n",
      "ğŸ“ Split file path: /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/splits/train.txt\n",
      "ğŸ“„ ==================================================\n",
      "ğŸ“‘ Total entries found in split file: 106\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 1/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g13_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 293\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 19, 38, 58, 77, 97, 116, 136, 155, 175, 194, 214, 233, 253, 272, 292]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 2/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g15_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 174\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 23, 34, 46, 57, 69, 80, 92, 103, 115, 126, 138, 149, 161, 173]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 3/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g19_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g19_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g19_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 4/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g17_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g17_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g17_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 153\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 10, 20, 30, 40, 50, 60, 70, 81, 91, 101, 111, 121, 131, 141, 152]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 5/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g12_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g12_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g12_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 273\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 18, 36, 54, 72, 90, 108, 126, 145, 163, 181, 199, 217, 235, 253, 272]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 6/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g20_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g20_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g20_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 175\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 23, 34, 46, 58, 69, 81, 92, 104, 116, 127, 139, 150, 162, 174]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 7/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g15_c07.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c07.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c07.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 164\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 10, 21, 32, 43, 54, 65, 76, 86, 97, 108, 119, 130, 141, 152, 163]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 8/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g15_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 152\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 151]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 9/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g15_c06.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c06.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 185\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 12, 24, 36, 49, 61, 73, 85, 98, 110, 122, 134, 147, 159, 171, 184]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 10/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g18_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g18_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g18_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 236\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 62, 78, 94, 109, 125, 141, 156, 172, 188, 203, 219, 235]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 11/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g16_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "  ğŸ“¸ Frames read so far: 325\n",
      "  ğŸ“¸ Frames read so far: 350\n",
      "  ğŸ“¸ Frames read so far: 375\n",
      "  ğŸ“¸ Frames read so far: 400\n",
      "  ğŸ“¸ Frames read so far: 425\n",
      "  ğŸ“¸ Frames read so far: 450\n",
      "  ğŸ“¸ Frames read so far: 475\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 492\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 32, 65, 98, 130, 163, 196, 229, 261, 294, 327, 360, 392, 425, 458, 491]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 12/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g21_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g21_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g21_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 23, 35, 47, 59, 71, 83, 95, 107, 119, 131, 143, 155, 167, 179]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 13/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g12_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g12_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g12_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 184\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 12, 24, 36, 48, 61, 73, 85, 97, 109, 122, 134, 146, 158, 170, 183]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 14/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g16_c06.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c06.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 315\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 20, 41, 62, 83, 104, 125, 146, 167, 188, 209, 230, 251, 272, 293, 314]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 15/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g18_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g18_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g18_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 174\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 23, 34, 46, 57, 69, 80, 92, 103, 115, 126, 138, 149, 161, 173]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 16/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g18_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g18_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g18_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 187\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 12, 24, 37, 49, 62, 74, 86, 99, 111, 124, 136, 148, 161, 173, 186]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 17/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g01_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g01_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g01_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 23, 35, 47, 59, 71, 83, 95, 107, 119, 131, 143, 155, 167, 179]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 18/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g15_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g15_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 195\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 12, 25, 38, 51, 64, 77, 90, 103, 116, 129, 142, 155, 168, 181, 194]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 19/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g13_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 311\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 20, 41, 62, 82, 103, 124, 144, 165, 186, 206, 227, 248, 268, 289, 310]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 20/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g01_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g01_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g01_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 206\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 27, 41, 54, 68, 82, 95, 109, 123, 136, 150, 164, 177, 191, 205]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 21/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g07_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g07_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g07_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 150\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99, 109, 119, 129, 139, 149]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 22/106\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g13_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 299\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 19, 39, 59, 79, 99, 119, 139, 158, 178, 198, 218, 238, 258, 278, 298]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 23/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g18_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 181\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 12, 24, 36, 48, 60, 72, 84, 96, 108, 120, 132, 144, 156, 168, 180]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 24/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g09_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g09_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g09_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 23, 35, 47, 59, 71, 83, 95, 107, 119, 131, 143, 155, 167, 179]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 25/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g18_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 181\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 12, 24, 36, 48, 60, 72, 84, 96, 108, 120, 132, 144, 156, 168, 180]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 26/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g19_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 27/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g19_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 28/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g22_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g22_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g22_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 219\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 14, 29, 43, 58, 72, 87, 101, 116, 130, 145, 159, 174, 188, 203, 218]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 29/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g22_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g22_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g22_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "  ğŸ“¸ Frames read so far: 325\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 339\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 22, 45, 67, 90, 112, 135, 157, 180, 202, 225, 247, 270, 292, 315, 338]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 30/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g16_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g16_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g16_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 23, 35, 47, 59, 71, 83, 95, 107, 119, 131, 143, 155, 167, 179]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 31/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g02_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g02_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g02_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 32/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g14_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g14_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g14_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 157\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 10, 20, 31, 41, 52, 62, 72, 83, 93, 104, 114, 124, 135, 145, 156]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 33/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g17_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g17_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g17_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 23, 35, 47, 59, 71, 83, 95, 107, 119, 131, 143, 155, 167, 179]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 34/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g20_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "  ğŸ“¸ Frames read so far: 325\n",
      "  ğŸ“¸ Frames read so far: 350\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 354\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 23, 47, 70, 94, 117, 141, 164, 188, 211, 235, 258, 282, 305, 329, 353]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 35/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g04_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g04_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g04_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 213\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 14, 28, 42, 56, 70, 84, 98, 113, 127, 141, 155, 169, 183, 197, 212]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 36/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g15_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g15_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g15_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 37/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g15_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g15_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g15_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 38/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g07_c06.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g07_c06.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g07_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 39/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g06_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g06_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g06_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 235\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 46, 62, 78, 93, 109, 124, 140, 156, 171, 187, 202, 218, 234]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 40/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g21_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 207\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 27, 41, 54, 68, 82, 96, 109, 123, 137, 151, 164, 178, 192, 206]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 41/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g08_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g08_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g08_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 201\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 26, 40, 53, 66, 80, 93, 106, 120, 133, 146, 160, 173, 186, 200]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 42/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g10_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g10_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g10_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 43/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g13_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g13_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g13_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 239\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 126, 142, 158, 174, 190, 206, 222, 238]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 44/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g15_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g15_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g15_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 45/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g20_c06.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c06.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "  ğŸ“¸ Frames read so far: 325\n",
      "  ğŸ“¸ Frames read so far: 350\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 358\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 23, 47, 71, 95, 119, 142, 166, 190, 214, 238, 261, 285, 309, 333, 357]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 46/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g10_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g10_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g10_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 47/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g24_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g24_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g24_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 213\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 14, 28, 42, 56, 70, 84, 98, 113, 127, 141, 155, 169, 183, 197, 212]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 48/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g10_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g10_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g10_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 49/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g05_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g05_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g05_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 163\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 10, 21, 32, 43, 54, 64, 75, 86, 97, 108, 118, 129, 140, 151, 162]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 50/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g04_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g04_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g04_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 23, 35, 47, 59, 71, 83, 95, 107, 119, 131, 143, 155, 167, 179]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 51/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g05_c06.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g05_c06.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g05_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 180\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 23, 35, 47, 59, 71, 83, 95, 107, 119, 131, 143, 155, 167, 179]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 52/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g17_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g17_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g17_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 204\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 27, 40, 54, 67, 81, 94, 108, 121, 135, 148, 162, 175, 189, 203]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 53/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g24_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g24_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g24_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 167\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 22, 33, 44, 55, 66, 77, 88, 99, 110, 121, 132, 143, 154, 166]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 54/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g01_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g01_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g01_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 55/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g24_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g24_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g24_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 209\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 27, 41, 55, 69, 83, 97, 110, 124, 138, 152, 166, 180, 194, 208]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 56/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g23_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g23_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g23_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "  ğŸ“¸ Frames read so far: 325\n",
      "  ğŸ“¸ Frames read so far: 350\n",
      "  ğŸ“¸ Frames read so far: 375\n",
      "  ğŸ“¸ Frames read so far: 400\n",
      "  ğŸ“¸ Frames read so far: 425\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 447\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 29, 59, 89, 118, 148, 178, 208, 237, 267, 297, 327, 356, 386, 416, 446]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 57/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g19_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g19_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 151\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 58/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g07_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g07_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g07_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 192\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 12, 25, 38, 50, 63, 76, 89, 101, 114, 127, 140, 152, 165, 178, 191]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 59/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g21_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 60/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g20_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 324\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 21, 43, 64, 86, 107, 129, 150, 172, 193, 215, 236, 258, 279, 301, 323]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 61/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g22_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g22_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g22_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 206\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 27, 41, 54, 68, 82, 95, 109, 123, 136, 150, 164, 177, 191, 205]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 62/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g11_c06.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g11_c06.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g11_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 152\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 151]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 63/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g11_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g11_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g11_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 210\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 27, 41, 55, 69, 83, 97, 111, 125, 139, 153, 167, 181, 195, 209]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 64/106\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g23_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g23_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g23_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "  ğŸ“¸ Frames read so far: 325\n",
      "  ğŸ“¸ Frames read so far: 350\n",
      "  ğŸ“¸ Frames read so far: 375\n",
      "  ğŸ“¸ Frames read so far: 400\n",
      "  ğŸ“¸ Frames read so far: 425\n",
      "  ğŸ“¸ Frames read so far: 450\n",
      "  ğŸ“¸ Frames read so far: 475\n",
      "  ğŸ“¸ Frames read so far: 500\n",
      "  ğŸ“¸ Frames read so far: 525\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 535\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 35, 71, 106, 142, 178, 213, 249, 284, 320, 356, 391, 427, 462, 498, 534]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 65/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g07_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g07_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g07_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 159\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 10, 21, 31, 42, 52, 63, 73, 84, 94, 105, 115, 126, 136, 147, 158]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 66/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g01_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g01_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g01_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 67/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g15_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g15_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g15_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 68/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g05_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g05_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g05_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 69/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g09_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 70/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g18_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g18_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g18_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 71/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g14_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g14_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g14_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 72/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g13_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g13_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g13_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 201\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 26, 40, 53, 66, 80, 93, 106, 120, 133, 146, 160, 173, 186, 200]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 73/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g02_c06.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g02_c06.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g02_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 74/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g23_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 75/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g09_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 206\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 27, 41, 54, 68, 82, 95, 109, 123, 136, 150, 164, 177, 191, 205]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 76/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g18_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g18_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g18_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 77/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g03_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g03_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g03_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 78/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g16_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 199\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 26, 39, 52, 66, 79, 92, 105, 118, 132, 145, 158, 171, 184, 198]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 79/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g20_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 80/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g12_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g12_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g12_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 229\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 30, 45, 60, 76, 91, 106, 121, 136, 152, 167, 182, 197, 212, 228]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 81/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g04_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g04_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g04_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 82/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g12_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g12_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g12_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 83/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g17_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g17_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g17_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 84/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g15_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g15_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g15_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 85/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g16_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 86/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g16_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g16_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 87/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g09_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 88/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g06_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g06_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g06_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 228\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 30, 45, 60, 75, 90, 105, 121, 136, 151, 166, 181, 196, 211, 227]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 89/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g21_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g21_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g21_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 90/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g20_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 91/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g23_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 92/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g03_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g03_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g03_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 93/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g19_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g19_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g19_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 94/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g23_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 203\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 26, 40, 53, 67, 80, 94, 107, 121, 134, 148, 161, 175, 188, 202]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 95/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g20_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 96/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g07_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g07_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g07_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 233\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 30, 46, 61, 77, 92, 108, 123, 139, 154, 170, 185, 201, 216, 232]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 97/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g01_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g01_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g01_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 98/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g11_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g11_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g11_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 99/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g06_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g06_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g06_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 100/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g20_c06.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c06.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 101/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g04_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g04_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g04_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 102/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g08_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g08_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g08_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 103/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g20_c07.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c07.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g20_c07.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 104/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g05_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g05_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g05_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 105/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g14_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g14_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g14_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 106/106\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g25_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g25_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g25_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ“¦ Stacking videos and labels into tensors\n",
      "âœ… Split loaded successfully\n",
      "ğŸ“ Videos tensor shape: torch.Size([106, 16, 3, 224, 224])\n",
      "ğŸ·ï¸  Labels tensor shape: torch.Size([106])\n",
      "ğŸ“„ ==================================================\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "ğŸ“‚ Loading TESTING data\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "ğŸ“„ ==================================================\n",
      "ğŸ“„ Loading split file\n",
      "ğŸ“ Split file path: /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/splits/test.txt\n",
      "ğŸ“„ ==================================================\n",
      "ğŸ“‘ Total entries found in split file: 24\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 1/24\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g16_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "  ğŸ“¸ Frames read so far: 325\n",
      "  ğŸ“¸ Frames read so far: 350\n",
      "  ğŸ“¸ Frames read so far: 375\n",
      "  ğŸ“¸ Frames read so far: 400\n",
      "  ğŸ“¸ Frames read so far: 425\n",
      "  ğŸ“¸ Frames read so far: 450\n",
      "  ğŸ“¸ Frames read so far: 475\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 482\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 481]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 2/24\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g17_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g17_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g17_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 214\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 14, 28, 42, 56, 71, 85, 99, 113, 127, 142, 156, 170, 184, 198, 213]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 3/24\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g16_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g16_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "  ğŸ“¸ Frames read so far: 325\n",
      "  ğŸ“¸ Frames read so far: 350\n",
      "  ğŸ“¸ Frames read so far: 375\n",
      "  ğŸ“¸ Frames read so far: 400\n",
      "  ğŸ“¸ Frames read so far: 425\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 446\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 29, 59, 89, 118, 148, 178, 207, 237, 267, 296, 326, 356, 385, 415, 445]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 4/24\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g25_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g25_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g25_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 179\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 23, 35, 47, 59, 71, 83, 94, 106, 118, 130, 142, 154, 166, 178]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 5/24\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g13_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g13_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 324\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 21, 43, 64, 86, 107, 129, 150, 172, 193, 215, 236, 258, 279, 301, 323]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 6/24\n",
      "ğŸ“ Relative path : class_1_Basketball/v_Basketball_g21_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g21_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_1_Basketball\n",
      "ğŸ”¢ Class index  : 0\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_1_Basketball/v_Basketball_g21_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 182\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 12, 24, 36, 48, 60, 72, 84, 96, 108, 120, 132, 144, 156, 168, 181]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 7/24\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g07_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g07_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g07_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 300\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 19, 39, 59, 79, 99, 119, 139, 159, 179, 199, 219, 239, 259, 279, 299]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 8/24\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g18_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g18_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 209\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 27, 41, 55, 69, 83, 97, 110, 124, 138, 152, 166, 180, 194, 208]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 9/24\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g20_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g20_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "  ğŸ“¸ Frames read so far: 250\n",
      "  ğŸ“¸ Frames read so far: 275\n",
      "  ğŸ“¸ Frames read so far: 300\n",
      "  ğŸ“¸ Frames read so far: 325\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 340\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 22, 45, 67, 90, 113, 135, 158, 180, 203, 226, 248, 271, 293, 316, 339]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 10/24\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g21_c06.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c06.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 11/24\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g21_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g21_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 12/24\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g02_c06.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g02_c06.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g02_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 239\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 126, 142, 158, 174, 190, 206, 222, 238]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 13/24\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g14_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g14_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g14_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 169\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 11, 22, 33, 44, 56, 67, 78, 89, 100, 112, 123, 134, 145, 156, 168]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 14/24\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g08_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g08_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g08_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 15/24\n",
      "ğŸ“ Relative path : class_2_Biking/v_Biking_g09_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g09_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_2_Biking\n",
      "ğŸ”¢ Class index  : 1\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_2_Biking/v_Biking_g09_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 196\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 13, 26, 39, 52, 65, 78, 91, 104, 117, 130, 143, 156, 169, 182, 195]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 16/24\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g07_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g07_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g07_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 17/24\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g08_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g08_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g08_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 228\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 30, 45, 60, 75, 90, 105, 121, 136, 151, 166, 181, 196, 211, 227]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 18/24\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g23_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g23_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 237\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 62, 78, 94, 110, 125, 141, 157, 173, 188, 204, 220, 236]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 19/24\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g14_c03.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g14_c03.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g14_c03.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 216\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 14, 28, 43, 57, 71, 86, 100, 114, 129, 143, 157, 172, 186, 200, 215]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 20/24\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g11_c05.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g11_c05.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g11_c05.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 21/24\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g09_c06.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c06.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g09_c06.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 239\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 126, 142, 158, 174, 190, 206, 222, 238]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 22/24\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g17_c02.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g17_c02.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g17_c02.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 23/24\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g24_c04.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g24_c04.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g24_c04.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ¬ ----------------------------------------------\n",
      "ğŸ¥ Processing video 24/24\n",
      "ğŸ“ Relative path : class_3_WalkingWithDog/v_WalkingWithDog_g17_c01.avi\n",
      "ğŸ“ Absolute path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g17_c01.avi\n",
      "ğŸ·ï¸  Class name   : class_3_WalkingWithDog\n",
      "ğŸ”¢ Class index  : 2\n",
      "ğŸ¬ ----------------------------------------------\n",
      "\n",
      "ğŸ¬ ==================================================\n",
      "ğŸ¥ Loading video\n",
      "ğŸ“ Video path      : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/dataset/class_3_WalkingWithDog/v_WalkingWithDog_g17_c01.avi\n",
      "ğŸ§® Target #frames  : 16\n",
      "ğŸ¬ ==================================================\n",
      "  ğŸ“¸ Frames read so far: 25\n",
      "  ğŸ“¸ Frames read so far: 50\n",
      "  ğŸ“¸ Frames read so far: 75\n",
      "  ğŸ“¸ Frames read so far: 100\n",
      "  ğŸ“¸ Frames read so far: 125\n",
      "  ğŸ“¸ Frames read so far: 150\n",
      "  ğŸ“¸ Frames read so far: 175\n",
      "  ğŸ“¸ Frames read so far: 200\n",
      "  ğŸ“¸ Frames read so far: 225\n",
      "â¹ï¸  End of video reached or frame read failed\n",
      "âœ… Total frames extracted: 240\n",
      "ğŸ“ Applying uniform temporal sampling\n",
      "ğŸ”¢ Sampled frame indices: [0, 15, 31, 47, 63, 79, 95, 111, 127, 143, 159, 175, 191, 207, 223, 239]\n",
      "ğŸ§© Frames after temporal processing: 16\n",
      "ğŸ¨ Applying ImageNet normalization & transforms\n",
      "ğŸ“¦ Final video tensor shape: torch.Size([16, 3, 224, 224])\n",
      "ğŸ¬ ==================================================\n",
      "\n",
      "\n",
      "ğŸ“¦ Stacking videos and labels into tensors\n",
      "âœ… Split loaded successfully\n",
      "ğŸ“ Videos tensor shape: torch.Size([24, 16, 3, 224, 224])\n",
      "ğŸ·ï¸  Labels tensor shape: torch.Size([24])\n",
      "ğŸ“„ ==================================================\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "âœ… Dataset summary\n",
      "-----------------------------------------------\n",
      "\n",
      "ğŸ“ Training videos : 106\n",
      "ğŸ§ª Testing videos  : 24\n",
      "ğŸ·ï¸  Total classes  : 3\n",
      "ğŸ“ Train tensor    : torch.Size([106, 16, 3, 224, 224])  (N, T, C, H, W)\n",
      "ğŸ“ Test tensor     : torch.Size([24, 16, 3, 224, 224])   (N, T, C, H, W)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# LOAD DATA USING OFFICIAL TRAIN / TEST SPLITS\n",
    "# ==========================================================\n",
    "# This section loads videos and labels using pre-defined\n",
    "# split files (e.g., train.txt, test.txt).\n",
    "#\n",
    "# Each split file is expected to contain relative paths\n",
    "# to video files, one per line, such as:\n",
    "#\n",
    "#   class_0/video_001.avi\n",
    "#   class_1/video_023.avi\n",
    "#\n",
    "# The parent folder name (class_*) is used as the label.\n",
    "# ==========================================================\n",
    "\n",
    "def load_split(split_file):\n",
    "    \"\"\"\n",
    "    Load videos and labels from a split file.\n",
    "\n",
    "    Args:\n",
    "        split_file (Path): Path to the split text file.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]:\n",
    "            - videos: Tensor of shape (N, T, C, H, W)\n",
    "            - labels: Tensor of shape (N,)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nğŸ“„ ==================================================\")\n",
    "    print(\"ğŸ“„ Loading split file\")\n",
    "    print(f\"ğŸ“ Split file path: {split_file}\")\n",
    "    print(\"ğŸ“„ ==================================================\")\n",
    "\n",
    "    videos = []  # Will store per-video tensors\n",
    "    labels = []  # Will store integer class labels\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 1: Read split file\n",
    "    # --------------------------------------------------\n",
    "    with open(split_file, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    print(f\"ğŸ“‘ Total entries found in split file: {len(lines)}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 2: Process each video entry\n",
    "    # --------------------------------------------------\n",
    "    for idx, line in enumerate(lines):\n",
    "        # Construct absolute video path\n",
    "        video_path = DATASET_ROOT / line\n",
    "\n",
    "        # Extract class name from path\n",
    "        # Example: \"class_2/video_003.avi\" â†’ \"class_2\"\n",
    "        class_name = line.split(\"/\")[0]\n",
    "\n",
    "        # Map class name to integer label\n",
    "        label = CLASS_TO_IDX[class_name]\n",
    "\n",
    "        print(\"\\nğŸ¬ ----------------------------------------------\")\n",
    "        print(f\"ğŸ¥ Processing video {idx + 1}/{len(lines)}\")\n",
    "        print(f\"ğŸ“ Relative path : {line}\")\n",
    "        print(f\"ğŸ“ Absolute path : {video_path}\")\n",
    "        print(f\"ğŸ·ï¸  Class name   : {class_name}\")\n",
    "        print(f\"ğŸ”¢ Class index  : {label}\")\n",
    "        print(\"ğŸ¬ ----------------------------------------------\")\n",
    "\n",
    "        # Load and preprocess video (T, C, H, W)\n",
    "        video_tensor = load_video(video_path)\n",
    "\n",
    "        # Append video tensor and label\n",
    "        videos.append(video_tensor)\n",
    "        labels.append(label)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 3: Stack videos and labels into tensors\n",
    "    # --------------------------------------------------\n",
    "    print(\"\\nğŸ“¦ Stacking videos and labels into tensors\")\n",
    "\n",
    "    videos_tensor = torch.stack(videos)        # Shape: (N, T, C, H, W)\n",
    "    labels_tensor = torch.tensor(labels)       # Shape: (N,)\n",
    "\n",
    "    print(\"âœ… Split loaded successfully\")\n",
    "    print(f\"ğŸ“ Videos tensor shape: {videos_tensor.shape}\")\n",
    "    print(f\"ğŸ·ï¸  Labels tensor shape: {labels_tensor.shape}\")\n",
    "    print(\"ğŸ“„ ==================================================\\n\")\n",
    "\n",
    "    return videos_tensor, labels_tensor\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD TRAINING DATA\n",
    "# ==========================================================\n",
    "print(\"\\n-----------------------------------------------\")\n",
    "print(\"ğŸ“‚ Loading TRAINING data\")\n",
    "print(\"-----------------------------------------------\\n\")\n",
    "\n",
    "X_train, y_train = load_split(SPLITS_DIR / \"train.txt\")\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD TESTING DATA\n",
    "# ==========================================================\n",
    "print(\"\\n-----------------------------------------------\")\n",
    "print(\"ğŸ“‚ Loading TESTING data\")\n",
    "print(\"-----------------------------------------------\\n\")\n",
    "\n",
    "X_test, y_test = load_split(SPLITS_DIR / \"test.txt\")\n",
    "\n",
    "# ==========================================================\n",
    "# DATASET SUMMARY\n",
    "# ==========================================================\n",
    "print(\"\\n-----------------------------------------------\")\n",
    "print(\"âœ… Dataset summary\")\n",
    "print(\"-----------------------------------------------\\n\")\n",
    "\n",
    "print(f\"ğŸ“ Training videos : {len(X_train)}\")\n",
    "print(f\"ğŸ§ª Testing videos  : {len(X_test)}\")\n",
    "print(f\"ğŸ·ï¸  Total classes  : {NUM_CLASSES}\")\n",
    "print(f\"ğŸ“ Train tensor    : {X_train.shape}  (N, T, C, H, W)\")\n",
    "print(f\"ğŸ“ Test tensor     : {X_test.shape}   (N, T, C, H, W)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57ca61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# VIDEO DATASET WITH OPTIONAL DATA AUGMENTATION\n",
    "# ==========================================================\n",
    "class VideoDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for video classification.\n",
    "\n",
    "    Each sample consists of:\n",
    "    - A video: sequence of frames (Tensor)\n",
    "    - A label: class index or class name\n",
    "\n",
    "    Data augmentation:\n",
    "    - Random horizontal flip is applied\n",
    "      ONLY when train=True\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: List[torch.Tensor],\n",
    "        y: List[int],\n",
    "        train: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "\n",
    "        Args:\n",
    "            X (List[Tensor]):\n",
    "                List of videos.\n",
    "                Each video is a Tensor of shape:\n",
    "                (num_frames, channels, height, width)\n",
    "\n",
    "            y (List[int]):\n",
    "                Corresponding labels for each video.\n",
    "\n",
    "            train (bool):\n",
    "                If True:\n",
    "                    - Apply data augmentation (horizontal flip)\n",
    "                If False:\n",
    "                    - No augmentation (used for validation/testing)\n",
    "        \"\"\"\n",
    "        # Store videos\n",
    "        self.X = X\n",
    "\n",
    "        # Store labels\n",
    "        self.y = y\n",
    "\n",
    "        # Flag to control augmentation behavior\n",
    "        self.train = train\n",
    "\n",
    "        # Define spatial augmentation:\n",
    "        # Randomly flips an image horizontally with 50% probability\n",
    "        #\n",
    "        # IMPORTANT:\n",
    "        # - This does NOT add new pixels\n",
    "        # - It only rearranges existing pixels\n",
    "        self.flip = transforms.RandomHorizontalFlip(p=0.5)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Return the total number of samples in the dataset.\n",
    "\n",
    "        This method is required by PyTorch's Dataset class\n",
    "        so that DataLoader knows how many samples exist.\n",
    "        \"\"\"\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"\"\"\n",
    "        Retrieve one sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int):\n",
    "                Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, int]:\n",
    "                - video: Tensor of shape\n",
    "                  (num_frames, channels, height, width)\n",
    "                - label: corresponding class label\n",
    "        \"\"\"\n",
    "        # Fetch the video at the given index\n",
    "        video = self.X[idx]\n",
    "\n",
    "        # Apply data augmentation ONLY during training\n",
    "        if self.train:\n",
    "            # Apply horizontal flip independently to each frame\n",
    "            #\n",
    "            # Why per-frame?\n",
    "            # - Each frame is treated as an image\n",
    "            # - Maintains temporal order\n",
    "            # - Simple and effective spatial augmentation\n",
    "            #\n",
    "            # torch.stack is used to reconstruct the video\n",
    "            # back into a single Tensor\n",
    "            video = torch.stack([self.flip(frame) for frame in video])\n",
    "\n",
    "        # Return video and its label\n",
    "        return video, self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0eaf95e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Data loaders initialized\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# DATALOADERS\n",
    "# ==========================================================\n",
    "train_loader = DataLoader(\n",
    "    VideoDataset(X_train, y_train, train=True),\n",
    "    batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    VideoDataset(X_test, y_test, train=False),\n",
    "    batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Data loaders initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c8e4a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Local Weight Path : /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/model/resnet18-f37072fd.pth\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# MODEL DEFINITIONS\n",
    "# ==========================================================\n",
    "# Path to your downloaded weights\n",
    "\n",
    "print(f\"* Local Weight Path : {LOCAL_WEIGHTS}\")\n",
    "\n",
    "class CNN2DTemporal(nn.Module):\n",
    "    def __init__(self, num_classes, local_weights_path=LOCAL_WEIGHTS):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load ResNet18 without downloading\n",
    "        base = models.resnet18(weights=None)\n",
    "        # Load local pretrained weights\n",
    "        if os.path.exists(local_weights_path):\n",
    "            print(f\"Loading ResNet18 weights from {local_weights_path}\")\n",
    "            state_dict = torch.load(local_weights_path, map_location=\"cpu\")\n",
    "            base.load_state_dict(state_dict)\n",
    "        else:\n",
    "            print(\"âš ï¸ Local weights not found, initializing randomly\")\n",
    "\n",
    "        # Remove classifier\n",
    "        self.backbone = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        feats = self.backbone(x).view(B, T, -1)\n",
    "        pooled = feats.mean(dim=1) + feats.max(dim=1)[0]\n",
    "        return self.fc(pooled)\n",
    "\n",
    "class CNN3D(nn.Module):\n",
    "    \"\"\"\n",
    "    3D CNN explicitly models spatiotemporal features\n",
    "    using 3D convolutions.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = models.video.r2plus1d_18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af423aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# TRAINING & EVALUATION FUNCTION\n",
    "# ==========================================================\n",
    "def train_and_evaluate(model, model_name):\n",
    "    print(f\"\\nğŸš€ Training {model_name}\")\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    start_train = time.time()\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for videos, labels in train_loader:\n",
    "            videos, labels = videos.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(videos), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}] - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_time = time.time() - start_train\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    start_inf = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for videos, labels in test_loader:\n",
    "            videos = videos.to(DEVICE)\n",
    "            outputs = model(videos)\n",
    "            preds.extend(torch.argmax(outputs, 1).cpu().numpy())\n",
    "            targets.extend(labels.numpy())\n",
    "\n",
    "    inf_time = (time.time() - start_inf) / len(targets)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(targets, preds),\n",
    "        \"precision\": precision_score(targets, preds, average=\"macro\"),\n",
    "        \"recall\": recall_score(targets, preds, average=\"macro\"),\n",
    "        \"f1\": f1_score(targets, preds, average=\"macro\"),\n",
    "        \"train_time\": train_time,\n",
    "        \"inf_time\": inf_time,\n",
    "        \"cm\": confusion_matrix(targets, preds)\n",
    "    }\n",
    "\n",
    "    print(f\"\\nğŸ“Š {model_name} Performance\")\n",
    "    for k, v in metrics.items():\n",
    "        if k not in [\"cm\"]:\n",
    "            print(f\"{k.replace('_',' ').title():<20}: {v:.4f}\")\n",
    "\n",
    "    sns.heatmap(metrics[\"cm\"], annot=True, fmt=\"d\")\n",
    "    plt.title(model_name)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe317536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ResNet18 weights from /home/jovyan/va-dataset/Student_2024ab05275_Video_Classification/model/resnet18-f37072fd.pth\n",
      "\n",
      "ğŸš€ Training 2D CNN + Temporal Pooling\n",
      "Epoch [1/5] - Loss: 0.4819\n",
      "Epoch [2/5] - Loss: 0.5219\n",
      "Epoch [3/5] - Loss: 0.0219\n",
      "Epoch [4/5] - Loss: 0.0009\n",
      "Epoch [5/5] - Loss: 0.1228\n",
      "\n",
      "ğŸ“Š 2D CNN + Temporal Pooling Performance\n",
      "Accuracy            : 1.0000\n",
      "Precision           : 1.0000\n",
      "Recall              : 1.0000\n",
      "F1                  : 1.0000\n",
      "Train Time          : 15.4184\n",
      "Inf Time            : 0.0129\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R2Plus1D_18_Weights.KINETICS400_V1`. You can also use `weights=R2Plus1D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/r2plus1d_18-91a641e6.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/r2plus1d_18-91a641e6.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120M/120M [00:01<00:00, 112MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training 3D CNN (R(2+1)D)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.6017\n",
      "Epoch [2/5] - Loss: 0.1070\n",
      "Epoch [3/5] - Loss: 0.0902\n",
      "Epoch [4/5] - Loss: 0.0249\n",
      "Epoch [5/5] - Loss: 1.3413\n",
      "\n",
      "ğŸ“Š 3D CNN (R(2+1)D) Performance\n",
      "Accuracy            : 0.9583\n",
      "Precision           : 0.9667\n",
      "Recall              : 0.9630\n",
      "F1                  : 0.9628\n",
      "Train Time          : 64.3795\n",
      "Inf Time            : 0.0219\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# RUN EXPERIMENTS\n",
    "# ==========================================================\n",
    "metrics_2d = train_and_evaluate(\n",
    "    CNN2DTemporal(NUM_CLASSES),\n",
    "    \"2D CNN + Temporal Pooling\"\n",
    ")\n",
    "\n",
    "metrics_3d = train_and_evaluate(\n",
    "    CNN3D(NUM_CLASSES),\n",
    "    \"3D CNN (R(2+1)D)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebb1a942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“ˆ DETAILED MODEL COMPARISON REPORT\n",
      "============================================================\n",
      "\n",
      "ğŸ”¹ Accuracy Comparison\n",
      "2D CNN Accuracy : 1.0000\n",
      "3D CNN Accuracy : 0.9583\n",
      "\n",
      "ğŸ”¹ Computational Efficiency\n",
      "2D CNN Training Time (s): 15.83\n",
      "3D CNN Training Time (s): 64.24\n",
      "2D CNN Inference Time / Video (s): 0.0133\n",
      "3D CNN Inference Time / Video (s): 0.0192\n",
      "\n",
      "ğŸ”¹ Qualitative Analysis\n",
      "âœ” The 2D CNN achieves competitive accuracy with significantly lower computational cost, making it suitable for real-time applications.\n",
      "\n",
      "ğŸ”¹ Final Conclusion:\n",
      "2D CNNs provide a strong baseline with efficient inference, while 3D CNNs offer improved performance at the cost of higher computation.\n",
      "\n",
      "âœ… Experiment completed successfully\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# DETAILED COMPARISON REPORT\n",
    "# ==========================================================\n",
    "\n",
    "def compare_models(metrics_2d, metrics_3d):\n",
    "    \"\"\"\n",
    "    Generate comparison charts and a detailed report\n",
    "    for 2D CNN vs 3D CNN models.\n",
    "\n",
    "    Args:\n",
    "        metrics_2d (dict): Metrics for 2D CNN\n",
    "        metrics_3d (dict): Metrics for 3D CNN\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Sanity checks\n",
    "    # ------------------------------------------------------\n",
    "    required_keys = {\"accuracy\", \"train_time\", \"inf_time\"}\n",
    "\n",
    "    if not required_keys.issubset(metrics_2d):\n",
    "        raise ValueError(\"metrics_2d missing required keys\")\n",
    "\n",
    "    if not required_keys.issubset(metrics_3d):\n",
    "        raise ValueError(\"metrics_3d missing required keys\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Extract metrics\n",
    "    # ------------------------------------------------------\n",
    "    models = [\"2D CNN\", \"3D CNN\"]\n",
    "\n",
    "    accuracy = [\n",
    "        metrics_2d[\"accuracy\"],\n",
    "        metrics_3d[\"accuracy\"]\n",
    "    ]\n",
    "\n",
    "    train_time = [\n",
    "        metrics_2d[\"train_time\"],\n",
    "        metrics_3d[\"train_time\"]\n",
    "    ]\n",
    "\n",
    "    inf_time = [\n",
    "        metrics_2d[\"inf_time\"],\n",
    "        metrics_3d[\"inf_time\"]\n",
    "    ]\n",
    "\n",
    "    # ======================================================\n",
    "    # CHART 1: Accuracy Comparison\n",
    "    # ======================================================\n",
    "    plt.figure()\n",
    "    plt.bar(models, accuracy)\n",
    "    plt.title(\"Model Accuracy Comparison\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "    # ======================================================\n",
    "    # CHART 2: Training Time Comparison\n",
    "    # ======================================================\n",
    "    plt.figure()\n",
    "    plt.bar(models, train_time)\n",
    "    plt.title(\"Training Time Comparison\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ======================================================\n",
    "    # CHART 3: Inference Time Comparison\n",
    "    # ======================================================\n",
    "    plt.figure()\n",
    "    plt.bar(models, inf_time)\n",
    "    plt.title(\"Inference Time per Video Comparison\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ======================================================\n",
    "    # TEXTUAL COMPARISON REPORT\n",
    "    # ======================================================\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“ˆ DETAILED MODEL COMPARISON REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Accuracy\n",
    "    print(\"\\nğŸ”¹ Accuracy Comparison\")\n",
    "    print(f\"2D CNN Accuracy : {metrics_2d['accuracy']:.4f}\")\n",
    "    print(f\"3D CNN Accuracy : {metrics_3d['accuracy']:.4f}\")\n",
    "\n",
    "    # Efficiency\n",
    "    print(\"\\nğŸ”¹ Computational Efficiency\")\n",
    "    print(f\"2D CNN Training Time (s)        : {metrics_2d['train_time']:.2f}\")\n",
    "    print(f\"3D CNN Training Time (s)        : {metrics_3d['train_time']:.2f}\")\n",
    "    print(f\"2D CNN Inference Time / Video(s): {metrics_2d['inf_time']:.4f}\")\n",
    "    print(f\"3D CNN Inference Time / Video(s): {metrics_3d['inf_time']:.4f}\")\n",
    "\n",
    "    # Qualitative analysis\n",
    "    print(\"\\nğŸ”¹ Qualitative Analysis\")\n",
    "    if metrics_3d[\"accuracy\"] > metrics_2d[\"accuracy\"]:\n",
    "        print(\n",
    "            \"âœ” The 3D CNN outperforms the 2D CNN by explicitly modeling \"\n",
    "            \"spatiotemporal patterns, making it more suitable for complex actions.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"âœ” The 2D CNN achieves competitive accuracy with significantly lower \"\n",
    "            \"computational cost, making it suitable for real-time applications.\"\n",
    "        )\n",
    "\n",
    "    # Final conclusion\n",
    "    print(\n",
    "        \"\\nğŸ”¹ Final Conclusion:\\n\"\n",
    "        \"2D CNNs provide a strong baseline with efficient inference, while \"\n",
    "        \"3D CNNs offer improved performance at the cost of higher computation.\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nâœ… Experiment completed successfully\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“ˆ DETAILED MODEL COMPARISON REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nğŸ”¹ Accuracy Comparison\")\n",
    "print(f\"2D CNN Accuracy : {metrics_2d['accuracy']:.4f}\")\n",
    "print(f\"3D CNN Accuracy : {metrics_3d['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ”¹ Computational Efficiency\")\n",
    "print(f\"2D CNN Training Time (s): {metrics_2d['train_time']:.2f}\")\n",
    "print(f\"3D CNN Training Time (s): {metrics_3d['train_time']:.2f}\")\n",
    "print(f\"2D CNN Inference Time / Video (s): {metrics_2d['inf_time']:.4f}\")\n",
    "print(f\"3D CNN Inference Time / Video (s): {metrics_3d['inf_time']:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ”¹ Qualitative Analysis\")\n",
    "if metrics_3d[\"accuracy\"] > metrics_2d[\"accuracy\"]:\n",
    "    print(\n",
    "        \"âœ” The 3D CNN outperforms the 2D CNN by explicitly modeling \"\n",
    "        \"spatiotemporal patterns, making it more suitable for complex actions.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"âœ” The 2D CNN achieves competitive accuracy with significantly lower \"\n",
    "        \"computational cost, making it suitable for real-time applications.\"\n",
    "    )\n",
    "\n",
    "print(\n",
    "    \"\\nğŸ”¹ Final Conclusion:\\n\"\n",
    "    \"2D CNNs provide a strong baseline with efficient inference, while \"\n",
    "    \"3D CNNs offer improved performance at the cost of higher computation.\"\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Experiment completed successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699bd8d3-145d-4563-add2-edb0e37b0bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
